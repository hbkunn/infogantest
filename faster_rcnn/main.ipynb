{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from utils.timer import Timer\n",
    "from utils.blob import im_list_to_blob\n",
    "#from fast_rcnn.nms_wrapper import nms\n",
    "#from rpn_msr.proposal_layer import proposal_layer as proposal_layer_py\n",
    "#from rpn_msr.anchor_target_layer import anchor_target_layer as anchor_target_layer_py\n",
    "#from rpn_msr.proposal_target_layer import proposal_target_layer as proposal_target_layer_py\n",
    "#from fast_rcnn.bbox_transform import bbox_transform_inv, clip_boxes\n",
    "\n",
    "import network\n",
    "from network import Conv2d, FC\n",
    "# from roi_pooling.modules.roi_pool_py import RoIPool\n",
    "from roi_pooling.modules.roi_pool import RoIPool\n",
    "from vgg16 import VGG16\n",
    "\n",
    "\n",
    "def nms_detections(pred_boxes, scores, nms_thresh, inds=None):\n",
    "    dets = np.hstack((pred_boxes,\n",
    "                      scores[:, np.newaxis])).astype(np.float32)\n",
    "    keep = nms(dets, nms_thresh)\n",
    "    if inds is None:\n",
    "        return pred_boxes[keep], scores[keep]\n",
    "    return pred_boxes[keep], scores[keep], inds[keep]\n",
    "\n",
    "\n",
    "class RPN(nn.Module):\n",
    "    _feat_stride = [16, ]\n",
    "    anchor_scales = [8, 16, 32]\n",
    "\n",
    "    def __init__(self):\n",
    "        super(RPN, self).__init__()\n",
    "\n",
    "        self.features = VGG16(bn=False)\n",
    "        self.conv1 = Conv2d(512, 512, 3, same_padding=True)\n",
    "        self.score_conv = Conv2d(512, len(self.anchor_scales) * 3 * 2, 1, relu=False, same_padding=False)\n",
    "        self.bbox_conv = Conv2d(512, len(self.anchor_scales) * 3 * 4, 1, relu=False, same_padding=False)\n",
    "\n",
    "        # loss\n",
    "        self.cross_entropy = None\n",
    "        self.los_box = None\n",
    "\n",
    "    @property\n",
    "    def loss(self):\n",
    "        return self.cross_entropy + self.loss_box * 10\n",
    "\n",
    "    def forward(self, im_data, im_info, gt_boxes=None, gt_ishard=None, dontcare_areas=None):\n",
    "        im_data = network.np_to_variable(im_data, is_cuda=True)\n",
    "        im_data = im_data.permute(0, 3, 1, 2)\n",
    "        features = self.features(im_data)\n",
    "\n",
    "        rpn_conv1 = self.conv1(features)\n",
    "\n",
    "        # rpn score\n",
    "        rpn_cls_score = self.score_conv(rpn_conv1)\n",
    "        rpn_cls_score_reshape = self.reshape_layer(rpn_cls_score, 2)\n",
    "        rpn_cls_prob = F.softmax(rpn_cls_score_reshape)\n",
    "        rpn_cls_prob_reshape = self.reshape_layer(rpn_cls_prob, len(self.anchor_scales)*3*2)\n",
    "\n",
    "        # rpn boxes\n",
    "        rpn_bbox_pred = self.bbox_conv(rpn_conv1)\n",
    "\n",
    "        # proposal layer\n",
    "        cfg_key = 'TRAIN' if self.training else 'TEST'\n",
    "        rois = self.proposal_layer(rpn_cls_prob_reshape, rpn_bbox_pred, im_info,\n",
    "                                   cfg_key, self._feat_stride, self.anchor_scales)\n",
    "\n",
    "        # generating training labels and build the rpn loss\n",
    "        if self.training:\n",
    "            assert gt_boxes is not None\n",
    "            rpn_data = self.anchor_target_layer(rpn_cls_score, gt_boxes, gt_ishard, dontcare_areas,\n",
    "                                                im_info, self._feat_stride, self.anchor_scales)\n",
    "            self.cross_entropy, self.loss_box = self.build_loss(rpn_cls_score_reshape, rpn_bbox_pred, rpn_data)\n",
    "\n",
    "        return features, rois\n",
    "\n",
    "    def build_loss(self, rpn_cls_score_reshape, rpn_bbox_pred, rpn_data):\n",
    "        # classification loss\n",
    "        rpn_cls_score = rpn_cls_score_reshape.permute(0, 2, 3, 1).contiguous().view(-1, 2)\n",
    "        rpn_label = rpn_data[0].view(-1)\n",
    "\n",
    "        rpn_keep = Variable(rpn_label.data.ne(-1).nonzero().squeeze()).cuda()\n",
    "        rpn_cls_score = torch.index_select(rpn_cls_score, 0, rpn_keep)\n",
    "        rpn_label = torch.index_select(rpn_label, 0, rpn_keep)\n",
    "\n",
    "        fg_cnt = torch.sum(rpn_label.data.ne(0))\n",
    "\n",
    "        rpn_cross_entropy = F.cross_entropy(rpn_cls_score, rpn_label)\n",
    "\n",
    "        # box loss\n",
    "        rpn_bbox_targets, rpn_bbox_inside_weights, rpn_bbox_outside_weights = rpn_data[1:]\n",
    "        rpn_bbox_targets = torch.mul(rpn_bbox_targets, rpn_bbox_inside_weights)\n",
    "        rpn_bbox_pred = torch.mul(rpn_bbox_pred, rpn_bbox_inside_weights)\n",
    "\n",
    "        rpn_loss_box = F.smooth_l1_loss(rpn_bbox_pred, rpn_bbox_targets, size_average=False) / (fg_cnt + 1e-4)\n",
    "\n",
    "        return rpn_cross_entropy, rpn_loss_box\n",
    "\n",
    "    @staticmethod\n",
    "    def reshape_layer(x, d):\n",
    "        input_shape = x.size()\n",
    "        # x = x.permute(0, 3, 1, 2)\n",
    "        # b c w h\n",
    "        x = x.view(\n",
    "            input_shape[0],\n",
    "            int(d),\n",
    "            int(float(input_shape[1] * input_shape[2]) / float(d)),\n",
    "            input_shape[3]\n",
    "        )\n",
    "        # x = x.permute(0, 2, 3, 1)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def proposal_layer(rpn_cls_prob_reshape, rpn_bbox_pred, im_info, cfg_key, _feat_stride, anchor_scales):\n",
    "        rpn_cls_prob_reshape = rpn_cls_prob_reshape.data.cpu().numpy()\n",
    "        rpn_bbox_pred = rpn_bbox_pred.data.cpu().numpy()\n",
    "        x = proposal_layer_py(rpn_cls_prob_reshape, rpn_bbox_pred, im_info, cfg_key, _feat_stride, anchor_scales)\n",
    "        x = network.np_to_variable(x, is_cuda=True)\n",
    "        return x.view(-1, 5)\n",
    "\n",
    "    @staticmethod\n",
    "    def anchor_target_layer(rpn_cls_score, gt_boxes, gt_ishard, dontcare_areas, im_info, _feat_stride, anchor_scales):\n",
    "        \"\"\"\n",
    "        rpn_cls_score: for pytorch (1, Ax2, H, W) bg/fg scores of previous conv layer\n",
    "        gt_boxes: (G, 5) vstack of [x1, y1, x2, y2, class]\n",
    "        gt_ishard: (G, 1), 1 or 0 indicates difficult or not\n",
    "        dontcare_areas: (D, 4), some areas may contains small objs but no labelling. D may be 0\n",
    "        im_info: a list of [image_height, image_width, scale_ratios]\n",
    "        _feat_stride: the downsampling ratio of feature map to the original input image\n",
    "        anchor_scales: the scales to the basic_anchor (basic anchor is [16, 16])\n",
    "        ----------\n",
    "        Returns\n",
    "        ----------\n",
    "        rpn_labels : (1, 1, HxA, W), for each anchor, 0 denotes bg, 1 fg, -1 dontcare\n",
    "        rpn_bbox_targets: (1, 4xA, H, W), distances of the anchors to the gt_boxes(may contains some transform)\n",
    "                        that are the regression objectives\n",
    "        rpn_bbox_inside_weights: (1, 4xA, H, W) weights of each boxes, mainly accepts hyper param in cfg\n",
    "        rpn_bbox_outside_weights: (1, 4xA, H, W) used to balance the fg/bg,\n",
    "        beacuse the numbers of bgs and fgs mays significiantly different\n",
    "        \"\"\"\n",
    "        rpn_cls_score = rpn_cls_score.data.cpu().numpy()\n",
    "        rpn_labels, rpn_bbox_targets, rpn_bbox_inside_weights, rpn_bbox_outside_weights = \\\n",
    "            anchor_target_layer_py(rpn_cls_score, gt_boxes, gt_ishard, dontcare_areas, im_info, _feat_stride, anchor_scales)\n",
    "\n",
    "        rpn_labels = network.np_to_variable(rpn_labels, is_cuda=True, dtype=torch.LongTensor)\n",
    "        rpn_bbox_targets = network.np_to_variable(rpn_bbox_targets, is_cuda=True)\n",
    "        rpn_bbox_inside_weights = network.np_to_variable(rpn_bbox_inside_weights, is_cuda=True)\n",
    "        rpn_bbox_outside_weights = network.np_to_variable(rpn_bbox_outside_weights, is_cuda=True)\n",
    "\n",
    "        return rpn_labels, rpn_bbox_targets, rpn_bbox_inside_weights, rpn_bbox_outside_weights\n",
    "\n",
    "    def load_from_npz(self, params):\n",
    "        # params = np.load(npz_file)\n",
    "        self.features.load_from_npz(params)\n",
    "\n",
    "        pairs = {'conv1.conv': 'rpn_conv/3x3', 'score_conv.conv': 'rpn_cls_score', 'bbox_conv.conv': 'rpn_bbox_pred'}\n",
    "        own_dict = self.state_dict()\n",
    "        for k, v in pairs.items():\n",
    "            key = '{}.weight'.format(k)\n",
    "            param = torch.from_numpy(params['{}/weights:0'.format(v)]).permute(3, 2, 0, 1)\n",
    "            own_dict[key].copy_(param)\n",
    "\n",
    "            key = '{}.bias'.format(k)\n",
    "            param = torch.from_numpy(params['{}/biases:0'.format(v)])\n",
    "            own_dict[key].copy_(param)\n",
    "\n",
    "\n",
    "class FasterRCNN(nn.Module):\n",
    "    n_classes = 21\n",
    "    classes = np.asarray(['__background__',\n",
    "                       'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "                       'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "                       'cow', 'diningtable', 'dog', 'horse',\n",
    "                       'motorbike', 'person', 'pottedplant',\n",
    "                       'sheep', 'sofa', 'train', 'tvmonitor'])\n",
    "    PIXEL_MEANS = np.array([[[193.67899132,158.25960826,198.46009229]]])\n",
    "    SCALES = (600,)\n",
    "    MAX_SIZE = 1000\n",
    "\n",
    "    def __init__(self, classes=None, debug=False):\n",
    "        super(FasterRCNN, self).__init__()\n",
    "\n",
    "        if classes is not None:\n",
    "            self.classes = classes\n",
    "            self.n_classes = len(classes)\n",
    "\n",
    "        self.rpn = RPN()\n",
    "        self.roi_pool = RoIPool(7, 7, 1.0/16)\n",
    "        self.fc6 = FC(512 * 7 * 7, 4096)\n",
    "        self.fc7 = FC(4096, 4096)\n",
    "        self.score_fc = FC(4096, self.n_classes, relu=False)\n",
    "        self.bbox_fc = FC(4096, self.n_classes * 4, relu=False)\n",
    "\n",
    "        # loss\n",
    "        self.cross_entropy = None\n",
    "        self.loss_box = None\n",
    "\n",
    "        # for log\n",
    "        self.debug = debug\n",
    "\n",
    "    @property\n",
    "    def loss(self):\n",
    "        # print self.cross_entropy\n",
    "        # print self.loss_box\n",
    "        # print self.rpn.cross_entropy\n",
    "        # print self.rpn.loss_box\n",
    "        return self.cross_entropy + self.loss_box * 10\n",
    "\n",
    "    def forward(self, im_data, im_info, gt_boxes=None, gt_ishard=None, dontcare_areas=None):\n",
    "        features, rois = self.rpn(im_data, im_info, gt_boxes, gt_ishard, dontcare_areas)\n",
    "\n",
    "        if self.training:\n",
    "            roi_data = self.proposal_target_layer(rois, gt_boxes, gt_ishard, dontcare_areas, self.n_classes)\n",
    "            rois = roi_data[0]\n",
    "\n",
    "        # roi pool\n",
    "        pooled_features = self.roi_pool(features, rois)\n",
    "        x = pooled_features.view(pooled_features.size()[0], -1)\n",
    "        x = self.fc6(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc7(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        cls_score = self.score_fc(x)\n",
    "        cls_prob = F.softmax(cls_score)\n",
    "        bbox_pred = self.bbox_fc(x)\n",
    "\n",
    "        if self.training:\n",
    "            self.cross_entropy, self.loss_box = self.build_loss(cls_score, bbox_pred, roi_data)\n",
    "\n",
    "        return cls_prob, bbox_pred, rois\n",
    "\n",
    "    def build_loss(self, cls_score, bbox_pred, roi_data):\n",
    "        # classification loss\n",
    "        label = roi_data[1].squeeze()\n",
    "        fg_cnt = torch.sum(label.data.ne(0))\n",
    "        bg_cnt = label.data.numel() - fg_cnt\n",
    "\n",
    "        # for log\n",
    "        if self.debug:\n",
    "            maxv, predict = cls_score.data.max(1)\n",
    "            self.tp = torch.sum(predict[:fg_cnt].eq(label.data[:fg_cnt])) if fg_cnt > 0 else 0\n",
    "            self.tf = torch.sum(predict[fg_cnt:].eq(label.data[fg_cnt:]))\n",
    "            self.fg_cnt = fg_cnt\n",
    "            self.bg_cnt = bg_cnt\n",
    "\n",
    "        ce_weights = torch.ones(cls_score.size()[1])\n",
    "        ce_weights[0] = float(fg_cnt) / bg_cnt\n",
    "        ce_weights = ce_weights.cuda()\n",
    "        cross_entropy = F.cross_entropy(cls_score, label, weight=ce_weights)\n",
    "\n",
    "        # bounding box regression L1 loss\n",
    "        bbox_targets, bbox_inside_weights, bbox_outside_weights = roi_data[2:]\n",
    "        bbox_targets = torch.mul(bbox_targets, bbox_inside_weights)\n",
    "        bbox_pred = torch.mul(bbox_pred, bbox_inside_weights)\n",
    "\n",
    "        loss_box = F.smooth_l1_loss(bbox_pred, bbox_targets, size_average=False) / (fg_cnt + 1e-4)\n",
    "\n",
    "        return cross_entropy, loss_box\n",
    "\n",
    "    @staticmethod\n",
    "    def proposal_target_layer(rpn_rois, gt_boxes, gt_ishard, dontcare_areas, num_classes):\n",
    "        \"\"\"\n",
    "        ----------\n",
    "        rpn_rois:  (1 x H x W x A, 5) [0, x1, y1, x2, y2]\n",
    "        gt_boxes: (G, 5) [x1 ,y1 ,x2, y2, class] int\n",
    "        # gt_ishard: (G, 1) {0 | 1} 1 indicates hard\n",
    "        dontcare_areas: (D, 4) [ x1, y1, x2, y2]\n",
    "        num_classes\n",
    "        ----------\n",
    "        Returns\n",
    "        ----------\n",
    "        rois: (1 x H x W x A, 5) [0, x1, y1, x2, y2]\n",
    "        labels: (1 x H x W x A, 1) {0,1,...,_num_classes-1}\n",
    "        bbox_targets: (1 x H x W x A, K x4) [dx1, dy1, dx2, dy2]\n",
    "        bbox_inside_weights: (1 x H x W x A, Kx4) 0, 1 masks for the computing loss\n",
    "        bbox_outside_weights: (1 x H x W x A, Kx4) 0, 1 masks for the computing loss\n",
    "        \"\"\"\n",
    "        rpn_rois = rpn_rois.data.cpu().numpy()\n",
    "        rois, labels, bbox_targets, bbox_inside_weights, bbox_outside_weights = \\\n",
    "            proposal_target_layer_py(rpn_rois, gt_boxes, gt_ishard, dontcare_areas, num_classes)\n",
    "        # print labels.shape, bbox_targets.shape, bbox_inside_weights.shape\n",
    "        rois = network.np_to_variable(rois, is_cuda=True)\n",
    "        labels = network.np_to_variable(labels, is_cuda=True, dtype=torch.LongTensor)\n",
    "        bbox_targets = network.np_to_variable(bbox_targets, is_cuda=True)\n",
    "        bbox_inside_weights = network.np_to_variable(bbox_inside_weights, is_cuda=True)\n",
    "        bbox_outside_weights = network.np_to_variable(bbox_outside_weights, is_cuda=True)\n",
    "\n",
    "        return rois, labels, bbox_targets, bbox_inside_weights, bbox_outside_weights\n",
    "\n",
    "    def interpret_faster_rcnn(self, cls_prob, bbox_pred, rois, im_info, im_shape, nms=True, clip=True, min_score=0.0):\n",
    "        # find class\n",
    "        scores, inds = cls_prob.data.max(1)\n",
    "        scores, inds = scores.cpu().numpy(), inds.cpu().numpy()\n",
    "\n",
    "        keep = np.where((inds > 0) & (scores >= min_score))\n",
    "        scores, inds = scores[keep], inds[keep]\n",
    "\n",
    "        # Apply bounding-box regression deltas\n",
    "        keep = keep[0]\n",
    "        box_deltas = bbox_pred.data.cpu().numpy()[keep]\n",
    "        box_deltas = np.asarray([\n",
    "            box_deltas[i, (inds[i] * 4): (inds[i] * 4 + 4)] for i in range(len(inds))\n",
    "        ], dtype=np.float)\n",
    "        boxes = rois.data.cpu().numpy()[keep, 1:5] / im_info[0][2]\n",
    "        pred_boxes = bbox_transform_inv(boxes, box_deltas)\n",
    "        if clip:\n",
    "            pred_boxes = clip_boxes(pred_boxes, im_shape)\n",
    "\n",
    "        # nms\n",
    "        if nms and pred_boxes.shape[0] > 0:\n",
    "            pred_boxes, scores, inds = nms_detections(pred_boxes, scores, 0.3, inds=inds)\n",
    "        print (inds.dtype)\n",
    "        print (self.classes.dtype)\n",
    "        print (self.classes[inds])\n",
    "        return pred_boxes, scores, self.classes[inds]\n",
    "\n",
    "    def detect(self, image, thr=0.3):\n",
    "        im_data, im_scales = self.get_image_blob_noscale(image)\n",
    "        im_info = np.array(\n",
    "            [[im_data.shape[1], im_data.shape[2], im_scales[0]]],\n",
    "            dtype=np.float32)\n",
    "        cls_prob, bbox_pred, rois = self(im_data, im_info)\n",
    "        pred_boxes, scores, classes = \\\n",
    "            self.interpret_faster_rcnn(cls_prob, bbox_pred, rois, im_info, image.shape, min_score=thr)\n",
    "        return pred_boxes, scores, classes\n",
    "\n",
    "    def get_image_blob_noscale(self, im):\n",
    "        im_orig = im.astype(np.float32, copy=True)\n",
    "        im_orig -= self.PIXEL_MEANS\n",
    "\n",
    "        processed_ims = [im]\n",
    "        im_scale_factors = [1.0]\n",
    "\n",
    "        blob = im_list_to_blob(processed_ims)\n",
    "\n",
    "        return blob, np.array(im_scale_factors)\n",
    "\n",
    "    def get_image_blob(self, im):\n",
    "        \"\"\"Converts an image into a network input.\n",
    "        Arguments:\n",
    "            im (ndarray): a color image in BGR order\n",
    "        Returns:\n",
    "            blob (ndarray): a data blob holding an image pyramid\n",
    "            im_scale_factors (list): list of image scales (relative to im) used\n",
    "                in the image pyramid\n",
    "        \"\"\"\n",
    "        im_orig = im.astype(np.float32, copy=True)\n",
    "        im_orig -= self.PIXEL_MEANS\n",
    "\n",
    "        im_shape = im_orig.shape\n",
    "        im_size_min = np.min(im_shape[0:2])\n",
    "        im_size_max = np.max(im_shape[0:2])\n",
    "        \n",
    "        processed_ims = []\n",
    "        im_scale_factors = []\n",
    "\n",
    "        for target_size in self.SCALES:\n",
    "            im_scale = float(target_size) / float(im_size_min)\n",
    "            # Prevent the biggest axis from being more than MAX_SIZE\n",
    "            if np.round(im_scale * im_size_max) > self.MAX_SIZE:\n",
    "                im_scale = float(self.MAX_SIZE) / float(im_size_max)\n",
    "            im = cv2.resize(im_orig, None, None, fx=im_scale, fy=im_scale,\n",
    "                            interpolation=cv2.INTER_LINEAR)\n",
    "            im = im_orig\n",
    "            im_scale_factors.append(im_scale)\n",
    "            processed_ims.append(im)\n",
    "\n",
    "        # Create a blob to hold the input images\n",
    "        blob = im_list_to_blob(processed_ims)\n",
    "\n",
    "        return blob, np.array(im_scale_factors)\n",
    "\n",
    "    def load_from_npz(self, params):\n",
    "        self.rpn.load_from_npz(params)\n",
    "\n",
    "        pairs = {'fc6.fc': 'fc6', 'fc7.fc': 'fc7', 'score_fc.fc': 'cls_score', 'bbox_fc.fc': 'bbox_pred'}\n",
    "        own_dict = self.state_dict()\n",
    "        for k, v in pairs.items():\n",
    "            key = '{}.weight'.format(k)\n",
    "            param = torch.from_numpy(params['{}/weights:0'.format(v)]).permute(1, 0)\n",
    "            own_dict[key].copy_(param)\n",
    "\n",
    "            key = '{}.bias'.format(k)\n",
    "            param = torch.from_numpy(params['{}/biases:0'.format(v)])\n",
    "            own_dict[key].copy_(param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 193.67899132  158.25960826  198.46009229]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "root_data = '../data/source/'\n",
    "root_label = '../data/annotations/'\n",
    "imageList = os.listdir(root_data)\n",
    "\n",
    "mean = np.zeros((3),dtype=np.float32)\n",
    "for i in imageList[0:-1]:\n",
    "    img = cv2.imread(root_data + i)\n",
    "    mean = (mean + img.mean(axis=0).mean(axis=0)/len(imageList[0:-1]))\n",
    "    \n",
    "print (mean)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "iterator = []\n",
    "biglst = []\n",
    "for i in imageList[0:-1]:\n",
    "    data_dict = {}\n",
    "    img = cv2.imread(root_data + i)    \n",
    "    label = cv2.imread(root_label + i, 2)\n",
    "    lst = []\n",
    "    data_dict['im_data'] = (img-mean).reshape(1,1200,1200,3)\n",
    "    for x in range(0, label.shape[0]):\n",
    "        for y in range(0, label.shape[1]):\n",
    "            if label[x,y] == 255:\n",
    "                lst.extend([x,y])\n",
    "    \n",
    "    store = np.asarray(lst,dtype=int).reshape(-1,2)\n",
    "    q = 0\n",
    "    bbox = np.zeros((store.shape[0],5),dtype=np.float32)\n",
    "    for i in store:\n",
    "        q+=1\n",
    "        x1,y1 = max(0,i[0]-16),max(0,i[1]-16)\n",
    "        x2,y2 = x1+32,y1+32\n",
    "        if x1+32>1200:\n",
    "            x1, x2 = (1200-32), 1200\n",
    "        if y1+32>1200:\n",
    "            y1, y2 = (1200-32), 1200\n",
    "        image_output = img[x1:x2,y1:y2,:]\n",
    "        biglst.append(image_output)\n",
    "        bbox[q-1] =  [x1,y1,x2,y2,1]\n",
    "    assert q == store.shape[0]\n",
    "    data_dict['gt_boxes'] = bbox.astype(np.float32)\n",
    "    iterator.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_info = np.asarray([[1200.,1200.,1]],dtype=np.float32)\n",
    "gt_ishard = None\n",
    "dontcare_areas = np.zeros((0,4), dtype=np.float32)\n",
    "element = iterator[0]\n",
    "im_data = element.get('im_data')\n",
    "#im_info = blobs['im_info']\n",
    "gt_boxes = element.get('gt_boxes')\n",
    "\n",
    "net = FasterRCNN(classes = np.array(['1','2']))\n",
    "net.cuda()\n",
    "rpn = net.rpn(im_data,im_info,gt_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
