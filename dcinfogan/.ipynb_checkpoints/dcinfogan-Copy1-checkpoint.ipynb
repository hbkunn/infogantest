{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Author: aaronlai\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class InfoGAN_Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, n_layer=3, n_conti=2, n_discrete=1,\n",
    "                 num_category=10, use_gpu=False, featmap_dim=256,\n",
    "                 n_channel=1):\n",
    "        \"\"\"\n",
    "        InfoGAN Discriminator, have additional outputs for latent codes.\n",
    "        Architecture brought from DCGAN.\n",
    "        \"\"\"\n",
    "        super(InfoGAN_Discriminator, self).__init__()\n",
    "        self.n_layer = n_layer\n",
    "        self.n_conti = n_conti\n",
    "        self.n_discrete = n_discrete\n",
    "        self.num_category = num_category\n",
    "\n",
    "        # Discriminator\n",
    "        self.featmap_dim = featmap_dim\n",
    "\n",
    "        convs = []\n",
    "        BNs = []\n",
    "        for layer in range(self.n_layer):\n",
    "            if layer == (self.n_layer - 1):\n",
    "                n_conv_in = n_channel\n",
    "            else:\n",
    "                n_conv_in = int(featmap_dim / (2**(layer + 1)))\n",
    "            n_conv_out = int(featmap_dim / (2**layer))\n",
    "\n",
    "            _conv = nn.Conv2d(n_conv_in, n_conv_out, kernel_size=5,\n",
    "                              stride=2, padding=2)\n",
    "            if use_gpu:\n",
    "                _conv = _conv.cuda()\n",
    "            convs.append(_conv)\n",
    "\n",
    "            if layer != (self.n_layer - 1):\n",
    "                _BN = nn.BatchNorm2d(n_conv_out)\n",
    "                if use_gpu:\n",
    "                    _BN = _BN.cuda()\n",
    "                BNs.append(_BN)\n",
    "\n",
    "        # output layer - prob(real) and auxiliary distributions Q(c_j|x)\n",
    "        n_hidden = featmap_dim * 4 * 4\n",
    "        n_output = 1 + n_conti + n_discrete * num_category\n",
    "        self.fc = nn.Linear(n_hidden, n_output)\n",
    "\n",
    "        # register all nn modules\n",
    "        self.convs = nn.ModuleList(convs)\n",
    "        self.BNs = nn.ModuleList(BNs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Output the probability of being in real dataset\n",
    "        plus the conditional distributions of latent codes.\n",
    "        \"\"\"\n",
    "        for layer in range(self.n_layer):\n",
    "            conv_layer = self.convs[self.n_layer - layer - 1]\n",
    "\n",
    "            if layer == 0:\n",
    "                x = F.leaky_relu(conv_layer(x), negative_slope=0.2)\n",
    "            else:\n",
    "                BN_layer = self.BNs[self.n_layer - layer - 1]\n",
    "                x = F.leaky_relu(BN_layer(conv_layer(x)), negative_slope=0.2)\n",
    "\n",
    "        x = x.view(-1, self.featmap_dim * 4 * 4)\n",
    "\n",
    "        # output layer\n",
    "        x = self.fc(x)\n",
    "        x[:, 0] = F.sigmoid(x[:, 0].clone())\n",
    "        for j in range(self.n_discrete):\n",
    "            start = 1 + self.n_conti + j * self.num_category\n",
    "            end = start + self.num_category\n",
    "            x[:, start:end] = F.softmax(x[:, start:end].clone())\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class InfoGAN_Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, noise_dim=10, n_layer=3, n_conti=2, n_discrete=1,\n",
    "                 num_category=10, use_gpu=False, featmap_dim=256, n_channel=1):\n",
    "        \"\"\"\n",
    "        InfoGAN Generator, have an additional input branch for latent codes.\n",
    "        Architecture brought from DCGAN.\n",
    "        \"\"\"\n",
    "        super(InfoGAN_Generator, self).__init__()\n",
    "        self.n_layer = n_layer\n",
    "        self.n_conti = n_conti\n",
    "        self.n_discrete = n_discrete\n",
    "        self.num_category = num_category\n",
    "\n",
    "        # calculate input dimension\n",
    "        n_input = noise_dim + n_conti + n_discrete * num_category\n",
    "\n",
    "        # Generator\n",
    "        self.featmap_dim = featmap_dim\n",
    "        self.fc_in = nn.Linear(n_input, featmap_dim * 4 * 4)\n",
    "\n",
    "        convs = []\n",
    "        BNs = []\n",
    "        for layer in range(self.n_layer):\n",
    "            if layer == 0:\n",
    "                n_conv_out = n_channel\n",
    "            else:\n",
    "                n_conv_out = featmap_dim / (2 ** (self.n_layer - layer))\n",
    "\n",
    "            n_conv_in = featmap_dim / (2 ** (self.n_layer - layer - 1))\n",
    "            n_width = 5 if layer == (self.n_layer - 1) else 6\n",
    "\n",
    "            _conv = nn.ConvTranspose2d(n_conv_in, n_conv_out, n_width,\n",
    "                                       stride=2, padding=2)\n",
    "\n",
    "            if use_gpu:\n",
    "                _conv = _conv.cuda()\n",
    "            convs.append(_conv)\n",
    "\n",
    "            if layer != 0:\n",
    "                _BN = nn.BatchNorm2d(n_conv_out)\n",
    "                if use_gpu:\n",
    "                    _BN = _BN.cuda()\n",
    "                BNs.append(_BN)\n",
    "\n",
    "        # register all nn modules\n",
    "        self.convs = nn.ModuleList(convs)\n",
    "        self.BNs = nn.ModuleList(BNs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input the random noise plus latent codes to generate fake images.\n",
    "        \"\"\"\n",
    "        x = self.fc_in(x)\n",
    "        x = x.view(-1, self.featmap_dim, 4, 4)\n",
    "\n",
    "        for layer in range(self.n_layer):\n",
    "            conv_layer = self.convs[self.n_layer - layer - 1]\n",
    "            if layer == (self.n_layer - 1):\n",
    "                x = F.tanh(conv_layer(x))\n",
    "            else:\n",
    "                BN_layer = self.BNs[self.n_layer - layer - 2]\n",
    "                x = F.relu(BN_layer(conv_layer(x)))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Author: aaronlai\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(batch_size=10, download=True):\n",
    "    \"\"\"\n",
    "    The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "    Transform them to Tensors of normalized range [-1, 1]\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                         (0.5, 0.5, 0.5))])\n",
    "    trainset = torchvision.datasets.MNIST(root='../data', train=True,\n",
    "                                          download=download,\n",
    "                                          transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.MNIST(root='../data', train=False,\n",
    "                                         download=download,\n",
    "                                         transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                             shuffle=False, num_workers=2)\n",
    "\n",
    "    return trainloader, testloader\n",
    "\n",
    "\n",
    "def gen_noise(n_instance, n_dim=2):\n",
    "    \"\"\"generate n-dim uniform random noise\"\"\"\n",
    "    return torch.Tensor(np.random.uniform(low=-1.0, high=1.0,\n",
    "                                          size=(n_instance, n_dim)))\n",
    "\n",
    "\n",
    "def gen_conti_codes(n_instance, n_conti, mean=0, std=1):\n",
    "    \"\"\"generate gaussian continuous codes with specified mean and std\"\"\"\n",
    "    codes = np.random.randn(n_instance, n_conti) * std + mean\n",
    "    return torch.Tensor(codes)\n",
    "\n",
    "\n",
    "def gen_discrete_code(n_instance, n_discrete, num_category=10):\n",
    "    \"\"\"generate discrete codes with n categories\"\"\"\n",
    "    codes = []\n",
    "    for i in range(n_discrete):\n",
    "        code = np.zeros((n_instance, num_category))\n",
    "        random_cate = np.random.randint(0, num_category, n_instance)\n",
    "        code[range(n_instance), random_cate] = 1\n",
    "        codes.append(code)\n",
    "\n",
    "    codes = np.concatenate(codes, 1)\n",
    "    return torch.Tensor(codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Variable containing:\n",
      "-0.5619 -0.5759 -0.0501  0.7748  0.8173 -0.2253 -0.2041  0.1070  0.9425  0.2985\n",
      "-0.7721 -0.5022 -0.7415  0.4669  0.2111 -0.4062 -0.4161 -0.0211  0.4009  0.6022\n",
      " 0.8112 -0.1573 -0.4208 -0.8612 -0.6203  0.4121  0.4028 -0.0320 -0.8657 -0.5539\n",
      "-0.2803  0.0650  0.6164  0.3515 -0.1804 -0.6027 -0.2142 -0.4378  0.0115  0.4682\n",
      " 0.8992 -0.0747 -0.3857 -0.2657 -0.0587  0.9938  0.4232  0.5902 -0.3354  0.1744\n",
      " 0.3869  0.7138 -0.4790  0.7496  0.3506  0.6166  0.4613  0.7808 -0.2872  0.0924\n",
      " 0.1025  0.1222  0.4651 -0.2540 -0.0238  0.7983 -0.0792 -0.4399  0.0748 -0.2969\n",
      " 0.7205 -0.2320 -0.0464 -0.1224 -0.9998 -0.3553  0.2423 -0.5924  0.0665  0.4739\n",
      "-0.9500  0.8510  0.7272 -0.7940  0.6544  0.4640 -0.6919 -0.1258 -0.3671  0.6257\n",
      " 0.1278 -0.7626  0.6199 -0.0241 -0.2509 -0.7392 -0.2772  0.8582  0.1457  0.2488\n",
      "[torch.FloatTensor of size 10x10]\n",
      ", Variable containing:\n",
      " 0.8891  0.2308\n",
      "-0.0382 -0.0731\n",
      "-0.7821  0.3871\n",
      "-0.1851 -1.0973\n",
      "-0.4095  0.3323\n",
      "-0.4840 -0.5791\n",
      "-1.2121  0.2350\n",
      "-0.6005  0.0907\n",
      "-0.2786 -0.6155\n",
      "-0.7302  1.0164\n",
      "[torch.FloatTensor of size 10x2]\n",
      ", Variable containing:\n",
      "    0     0     0     0     1     0     0     0     0     0\n",
      "    1     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     1     0     0     0     0     0     0\n",
      "    0     0     0     0     0     1     0     0     0     0\n",
      "    0     0     0     0     0     1     0     0     0     0\n",
      "    0     0     1     0     0     0     0     0     0     0\n",
      "    0     1     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     1     0     0     0\n",
      "    0     1     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     1     0     0     0     0     0\n",
      "[torch.FloatTensor of size 10x10]\n",
      ")\n",
      "('fake_inputs', Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      " -7.2406e-02 -2.4722e-02 -8.5607e-02  ...   9.0379e-02 -2.1437e-02  1.0798e-01\n",
      " -7.9983e-02 -1.2536e-02 -2.0317e-02  ...  -1.1255e-01 -4.3965e-02 -1.6773e-02\n",
      " -4.7511e-02 -6.3672e-02  4.8612e-02  ...   1.0173e-01 -1.3409e-01 -7.7242e-02\n",
      "                 ...                   ⋱                   ...                \n",
      " -1.8503e-01  3.1508e-02 -1.3855e-01  ...   1.0874e-01  1.3067e-01  5.8322e-02\n",
      " -1.0072e-01 -1.0722e-02 -3.0842e-03  ...   8.1865e-02  3.8711e-02  1.3131e-02\n",
      " -1.1909e-01  1.8751e-01 -8.1896e-02  ...   8.6329e-02 -8.7864e-02 -1.3610e-03\n",
      "     ⋮ \n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      " -3.5554e-03  1.6768e-02 -4.2790e-02  ...   5.0200e-02 -2.7903e-02  1.1790e-01\n",
      " -7.2105e-02 -4.5432e-02 -1.4957e-02  ...  -8.3098e-02 -1.4615e-02 -7.4371e-02\n",
      " -6.9738e-03  3.3474e-02 -5.4214e-02  ...   2.9243e-02  7.3322e-03 -2.9483e-02\n",
      "                 ...                   ⋱                   ...                \n",
      " -8.3245e-02  3.6032e-03 -9.5782e-02  ...   5.8776e-02  1.7528e-01  4.9472e-02\n",
      " -3.2037e-02 -5.8455e-03  8.0516e-02  ...   3.6123e-02  2.1818e-02 -5.4776e-03\n",
      " -1.9778e-02  1.2791e-01 -6.2465e-02  ...   1.4589e-01 -7.8423e-02  3.2142e-03\n",
      "     ⋮ \n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      " -6.2354e-02 -3.1358e-02  7.5253e-03  ...  -5.6189e-02 -1.5562e-02  6.1826e-02\n",
      " -6.1972e-02 -4.2467e-02 -4.0031e-02  ...  -4.1098e-02 -4.1328e-02 -9.6853e-03\n",
      "  2.3250e-02 -4.6154e-02 -2.2311e-02  ...   4.8222e-03  7.8944e-03  4.3673e-02\n",
      "                 ...                   ⋱                   ...                \n",
      " -4.5911e-02  7.5134e-02 -1.2476e-01  ...   2.8471e-02 -7.9413e-02  3.1516e-02\n",
      " -1.9471e-02 -3.2077e-02 -5.6415e-02  ...  -1.6594e-01 -7.4042e-02 -6.4169e-02\n",
      "  2.8281e-02  1.2904e-01  4.4497e-02  ...   2.6105e-01 -6.5243e-02 -3.8442e-03\n",
      "...   \n",
      "     ⋮ \n",
      "\n",
      "(7 ,0 ,.,.) = \n",
      " -3.5795e-02 -3.9849e-02  3.5864e-02  ...   3.7080e-02 -7.1498e-02  2.8797e-02\n",
      " -7.7316e-02 -4.5459e-02 -5.2615e-02  ...  -6.2940e-02  1.7696e-02  1.4566e-02\n",
      " -6.9592e-02  2.9489e-02 -2.4476e-02  ...  -7.7990e-02 -1.8524e-02  4.8135e-02\n",
      "                 ...                   ⋱                   ...                \n",
      "  2.7361e-02  1.3679e-01 -4.3895e-02  ...   5.8601e-02 -7.0861e-02 -7.1525e-02\n",
      " -4.7708e-02 -3.6779e-02 -3.0378e-04  ...  -8.2019e-02 -8.6116e-02 -1.2766e-02\n",
      " -3.4044e-02  1.5236e-01 -1.4014e-02  ...   1.3062e-01 -6.3858e-02 -3.1381e-03\n",
      "     ⋮ \n",
      "\n",
      "(8 ,0 ,.,.) = \n",
      " -6.3151e-03 -8.5810e-02 -2.3475e-02  ...   8.5898e-02 -7.5242e-02  7.4183e-02\n",
      " -6.6766e-02 -4.3722e-02 -2.5652e-02  ...   4.8166e-03  2.9011e-02  4.3388e-02\n",
      " -2.6499e-02 -4.1908e-02 -4.4017e-02  ...   3.4459e-02 -5.4253e-02  7.2807e-02\n",
      "                 ...                   ⋱                   ...                \n",
      " -5.8729e-02  3.1803e-02 -1.9001e-01  ...   6.0601e-02  4.8479e-03  1.1774e-01\n",
      "  7.6207e-03 -1.6142e-02 -1.0676e-01  ...  -6.9484e-02  1.4129e-02  5.0010e-02\n",
      " -8.0369e-02  1.1809e-01 -7.0792e-02  ...   4.4745e-02 -4.1282e-02  5.4274e-02\n",
      "     ⋮ \n",
      "\n",
      "(9 ,0 ,.,.) = \n",
      " -1.1103e-01  2.8470e-03  3.5440e-02  ...   1.1952e-02 -6.6230e-02  3.5047e-02\n",
      " -9.4979e-02 -5.2864e-02  2.4376e-02  ...  -2.0531e-02  1.4660e-02  3.9420e-02\n",
      "  2.4941e-02  1.4291e-02  8.3539e-03  ...   4.8813e-02 -1.9396e-02  1.0106e-02\n",
      "                 ...                   ⋱                   ...                \n",
      " -3.8819e-02  1.4598e-01 -1.3543e-01  ...   1.3252e-01  1.2262e-01  1.0728e-01\n",
      " -5.5090e-02 -3.7934e-02 -6.7680e-02  ...   5.3338e-02 -7.0026e-04  4.7978e-02\n",
      " -7.7416e-02  5.7235e-02 -4.3287e-02  ...   2.3558e-01 -8.1294e-02 -1.4617e-02\n",
      "[torch.FloatTensor of size 10x1x28x28]\n",
      ")\n",
      "(Variable containing:\n",
      " 0.3449  0.3977  0.1992  0.1213  0.3232  0.3408 -0.6398 -0.4189 -0.2145 -0.8002\n",
      "-0.0884 -0.7131  0.7105  0.4518  0.7797  0.5083  0.5528 -0.2736  0.7455  0.3121\n",
      " 0.0295  0.7799 -0.1372 -0.5876  0.1616  0.5875  0.1236  0.3129  0.9912 -0.5813\n",
      "-0.0583  0.5792 -0.4208 -0.4329 -0.5549 -0.5212  0.7369  0.5220 -0.8683 -0.0049\n",
      "-0.7164 -0.8057  0.7047 -0.3409 -0.1331 -0.8762  0.5660 -0.1234  0.2472 -0.7741\n",
      "-0.0210 -0.6658  0.4539  0.3313 -0.0340  0.4654  0.2541  0.2077  0.9818 -0.9253\n",
      " 0.4803 -0.1433 -0.5872  0.0763  0.8354  0.5863  0.3468 -0.1203 -0.7465  0.8912\n",
      " 0.3238 -0.6770  0.2668 -0.2102 -0.9092 -0.0607 -0.7468 -0.6058  0.0194  0.9810\n",
      "-0.2150  0.3292 -0.9625 -0.4011 -0.1982  0.9790 -0.1591  0.8456  0.6355  0.6738\n",
      "-0.5887 -0.5405 -0.5063  0.4652 -0.0667  0.0319  0.7672 -0.1861 -0.1121 -0.6060\n",
      "[torch.FloatTensor of size 10x10]\n",
      ", Variable containing:\n",
      "-0.9687 -0.9260\n",
      " 0.4660 -0.0669\n",
      "-0.5359  0.6946\n",
      " 0.5732  0.1403\n",
      "-0.6786  0.0736\n",
      " 1.1300 -0.2268\n",
      " 0.8570  0.6798\n",
      "-0.1067 -0.7537\n",
      "-0.9747  0.0227\n",
      " 0.0524  0.5374\n",
      "[torch.FloatTensor of size 10x2]\n",
      ", Variable containing:\n",
      "    0     0     0     0     1     0     0     0     0     0\n",
      "    0     1     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     0     1     0\n",
      "    0     0     0     0     0     1     0     0     0     0\n",
      "    0     0     0     0     1     0     0     0     0     0\n",
      "    0     0     0     0     1     0     0     0     0     0\n",
      "    0     0     0     0     1     0     0     0     0     0\n",
      "    0     0     0     0     0     1     0     0     0     0\n",
      "    0     0     0     0     0     0     1     0     0     0\n",
      "[torch.FloatTensor of size 10x10]\n",
      ")\n",
      "('fake_inputs', Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      " -1.6474e-02 -5.6985e-02 -4.9162e-02  ...   3.0029e-02  8.4714e-03  6.0374e-02\n",
      " -4.2326e-02 -6.8527e-02 -6.2665e-02  ...  -6.5409e-02 -5.9613e-02 -3.8349e-02\n",
      "  1.4117e-02 -4.8132e-02  1.0782e-01  ...   8.0743e-02  3.6986e-02 -3.5301e-02\n",
      "                 ...                   ⋱                   ...                \n",
      " -7.0377e-02 -3.6144e-02 -1.9495e-01  ...  -4.7629e-02 -2.7468e-02 -3.6264e-02\n",
      " -6.3337e-02  2.6562e-02 -1.0174e-01  ...  -7.5850e-02  3.2880e-02 -6.4048e-05\n",
      "  7.2571e-03  1.4341e-01 -1.0050e-02  ...   1.6834e-01 -3.5807e-02  4.3038e-02\n",
      "     ⋮ \n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      " -8.6050e-02 -6.3310e-02 -1.3599e-01  ...   9.6517e-02  2.0217e-02  1.1150e-01\n",
      " -5.8177e-02 -4.4126e-02 -6.3775e-02  ...  -2.8255e-02  2.8265e-02 -6.5085e-02\n",
      " -5.2648e-02  5.0905e-02  3.8392e-03  ...   9.4275e-02 -5.5730e-02 -5.5759e-02\n",
      "                 ...                   ⋱                   ...                \n",
      " -4.1700e-02  1.0448e-02 -1.7437e-01  ...   8.7624e-02 -1.4233e-02 -4.7661e-03\n",
      " -1.3599e-01  1.8294e-02  3.7760e-02  ...   9.1913e-03 -1.9885e-02 -1.4898e-02\n",
      " -7.2701e-02  1.9342e-01  2.7505e-02  ...  -9.8220e-03 -5.2249e-02  5.2534e-02\n",
      "     ⋮ \n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      " -5.9070e-02 -4.8472e-03  5.9838e-03  ...   5.4945e-02  2.2389e-02  8.7036e-02\n",
      " -4.3595e-02 -1.4288e-02 -1.4996e-03  ...  -1.7543e-02  8.0733e-02 -1.3067e-01\n",
      " -6.2279e-02 -1.8996e-02  9.2793e-02  ...   8.5821e-02 -3.9238e-02  5.1736e-02\n",
      "                 ...                   ⋱                   ...                \n",
      " -3.9429e-02  2.4118e-02 -1.6002e-01  ...  -2.4776e-02 -1.0335e-01 -6.7394e-02\n",
      " -7.6874e-02  2.2189e-05 -8.2563e-02  ...  -6.5304e-02 -5.3134e-02  1.2155e-02\n",
      "  2.3637e-02  1.2004e-01 -1.4313e-04  ...   2.0173e-01 -6.4825e-02 -3.7427e-03\n",
      "...   \n",
      "     ⋮ \n",
      "\n",
      "(7 ,0 ,.,.) = \n",
      "  2.8294e-02 -4.7793e-02  5.4260e-03  ...  -1.2519e-02 -3.3733e-02  6.7454e-02\n",
      " -9.1105e-02 -3.3907e-02 -6.6096e-02  ...   7.4129e-02 -4.3259e-02  4.1415e-03\n",
      " -3.5808e-02  2.4874e-02  1.8916e-02  ...  -1.1334e-01 -3.8099e-03 -6.6496e-02\n",
      "                 ...                   ⋱                   ...                \n",
      " -9.1112e-02 -2.0932e-03 -2.2461e-01  ...   3.7968e-02  2.3372e-02 -1.0616e-01\n",
      " -1.2329e-01 -5.8427e-02  2.5938e-02  ...  -1.0931e-01  7.7912e-02 -4.2770e-02\n",
      " -8.5688e-02  2.5517e-01 -2.5582e-02  ...   1.4349e-01 -7.9232e-02 -5.2861e-02\n",
      "     ⋮ \n",
      "\n",
      "(8 ,0 ,.,.) = \n",
      " -2.0210e-02  1.6347e-02 -1.9483e-02  ...   5.3600e-02 -6.6860e-03  5.6845e-02\n",
      " -8.8089e-02 -3.5215e-02 -6.5883e-02  ...  -5.3750e-03  2.3641e-04 -6.2634e-02\n",
      " -1.0391e-01 -3.9701e-02  9.2080e-02  ...  -7.4244e-02 -9.5554e-02 -1.2295e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -1.1671e-01  6.8129e-02 -3.0492e-01  ...   1.2283e-02 -8.3251e-02 -1.0107e-01\n",
      " -5.0486e-02  2.6066e-02  2.9936e-02  ...  -8.2004e-02 -1.2808e-02  1.8557e-02\n",
      "  2.6457e-02  2.1373e-01 -2.0378e-02  ...   1.5704e-01 -5.6958e-02  2.8977e-02\n",
      "     ⋮ \n",
      "\n",
      "(9 ,0 ,.,.) = \n",
      " -4.5247e-02 -5.6032e-02 -6.5920e-02  ...   2.1721e-02  4.0815e-02  2.6658e-02\n",
      " -3.4683e-02 -4.4893e-02  4.6154e-02  ...  -1.3587e-01  1.4185e-02 -7.3115e-02\n",
      " -1.2838e-01  4.9500e-02  2.1671e-02  ...   1.0443e-01  6.9956e-03  7.2496e-03\n",
      "                 ...                   ⋱                   ...                \n",
      " -9.4431e-02 -1.5701e-02 -1.9453e-02  ...  -1.4250e-02  1.6480e-02 -5.2883e-02\n",
      " -6.9551e-02 -3.2272e-02  2.6982e-02  ...  -1.5743e-02 -1.3619e-02 -5.7521e-03\n",
      "  1.1699e-02  7.7963e-02 -2.5885e-02  ...   1.2020e-01 -8.9729e-02  1.7173e-02\n",
      "[torch.FloatTensor of size 10x1x28x28]\n",
      ")\n",
      "(Variable containing:\n",
      " 0.5854  0.2032 -0.6898 -0.4199 -0.7840 -0.1962  0.3639  0.4888 -0.9604  0.6645\n",
      " 0.0795  0.1412  0.8791 -0.7084  0.5689  0.1490 -0.4706 -0.9474  0.7065  0.1606\n",
      " 0.8895 -0.4462 -0.5743  0.0437  0.9085  0.4513 -0.7322 -0.2046 -0.0759  0.7030\n",
      "-0.8534 -0.1069 -0.9878 -0.1251 -0.1727  0.6169  0.6301 -0.5241 -0.9019  0.1338\n",
      " 0.5028 -0.8927  0.9157  0.1301  0.9389 -0.3328 -0.8865  0.2221  0.3395  0.2072\n",
      "-0.7294 -0.3327  0.2957 -0.7097 -0.6245  0.5575 -0.0248 -0.6067  0.9630 -0.2519\n",
      "-0.2483  0.6467  0.6817  0.3284  0.5038 -0.8995  0.1652 -0.3287  0.9111  0.0944\n",
      " 0.9217  0.5974  0.5272 -0.0303 -0.8436 -0.6984  0.4091  0.7737 -0.5242  0.0481\n",
      " 0.9407  0.6304 -0.6622  0.4805  0.9898  0.4601 -0.8775  0.9978 -0.6618 -0.7457\n",
      " 0.5202  0.7589 -0.4833 -0.6885  0.9446  0.8572 -0.2036  0.8951 -0.8454 -0.7715\n",
      "[torch.FloatTensor of size 10x10]\n",
      ", Variable containing:\n",
      " 1.0674  0.0193\n",
      " 0.2599 -0.0798\n",
      "-0.0882  0.5234\n",
      " 0.0425 -0.4427\n",
      " 0.1609  0.0951\n",
      "-0.7528  0.8867\n",
      "-0.7149 -0.7084\n",
      " 0.1023 -0.3095\n",
      "-0.3040 -0.5759\n",
      "-0.0713  0.7727\n",
      "[torch.FloatTensor of size 10x2]\n",
      ", Variable containing:\n",
      "    0     0     0     0     0     0     0     0     1     0\n",
      "    0     0     0     1     0     0     0     0     0     0\n",
      "    0     0     0     0     0     1     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     1     0\n",
      "    0     0     0     1     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     1\n",
      "    0     0     0     0     1     0     0     0     0     0\n",
      "    0     0     0     0     0     0     1     0     0     0\n",
      "    1     0     0     0     0     0     0     0     0     0\n",
      "    1     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 10x10]\n",
      ")\n",
      "('fake_inputs', Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      " -5.1367e-02 -1.1694e-01 -1.5627e-02  ...  -7.9849e-02 -2.8784e-02  5.6414e-02\n",
      " -3.8771e-02 -4.9658e-02 -9.4532e-02  ...  -6.2118e-02 -4.4523e-02 -2.6540e-02\n",
      " -3.5428e-02  3.3224e-02 -5.2636e-02  ...   1.5843e-01 -4.8180e-02 -1.4136e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.4636e-02 -3.6776e-03 -2.3370e-01  ...   1.9465e-01 -9.2666e-03 -6.9956e-02\n",
      " -1.0617e-01  5.1513e-03 -7.7231e-03  ...  -2.7820e-02  1.2239e-03 -4.0568e-02\n",
      " -4.8491e-02  1.8155e-01 -4.7077e-02  ...   1.4994e-01 -8.1939e-02  4.1943e-02\n",
      "     ⋮ \n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      " -5.6624e-02 -1.3471e-01  1.7312e-04  ...   2.8725e-02 -2.9981e-02  7.9477e-02\n",
      " -2.9799e-02 -4.8763e-02 -7.0512e-02  ...  -4.2965e-02  5.2386e-02 -4.0463e-02\n",
      " -3.9115e-02 -1.9234e-02 -2.0109e-02  ...   1.8279e-01 -8.1206e-02  1.4831e-02\n",
      "                 ...                   ⋱                   ...                \n",
      "  3.2484e-02  7.3509e-03 -2.1948e-01  ...   5.8190e-02  1.4268e-02 -2.4151e-02\n",
      " -1.1165e-01  3.4492e-02 -1.1465e-01  ...  -6.8494e-03 -2.2990e-03 -3.9392e-02\n",
      " -4.5790e-02  1.9813e-01 -3.5473e-03  ...   1.5669e-01 -6.1922e-02  1.2404e-02\n",
      "     ⋮ \n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      " -2.6714e-02 -4.0873e-02 -7.6898e-02  ...   2.1836e-02 -1.0343e-02  6.3865e-02\n",
      " -7.4975e-02 -3.9086e-02 -5.9032e-03  ...  -2.5839e-02  8.1609e-03 -1.0076e-01\n",
      " -1.3848e-02  3.6755e-04  8.0774e-02  ...   1.1636e-01 -7.6477e-02 -5.0073e-02\n",
      "                 ...                   ⋱                   ...                \n",
      "  3.8684e-02  2.4229e-02 -1.1727e-01  ...   9.5890e-02 -3.1271e-02 -1.5026e-01\n",
      " -8.9904e-02  4.2980e-02 -1.3530e-02  ...  -1.5608e-02 -4.3485e-02 -5.3347e-02\n",
      " -4.4931e-02  1.5954e-01 -4.5394e-02  ...   1.3678e-01 -7.2924e-02 -2.2119e-02\n",
      "...   \n",
      "     ⋮ \n",
      "\n",
      "(7 ,0 ,.,.) = \n",
      "  1.5468e-02 -5.6723e-02 -4.7676e-02  ...   3.5809e-02 -5.2757e-02  1.7104e-02\n",
      " -2.3316e-02 -5.3755e-02 -7.7927e-02  ...   8.6904e-02  2.0535e-02 -2.7735e-02\n",
      " -2.8314e-02  4.3333e-02  3.6039e-02  ...   1.5941e-01 -4.7031e-02 -7.7414e-02\n",
      "                 ...                   ⋱                   ...                \n",
      " -4.6723e-02  1.1596e-01 -2.2269e-01  ...   1.4691e-01 -1.2162e-01 -1.4171e-01\n",
      " -6.9459e-02 -9.3332e-03 -7.0784e-02  ...  -3.3479e-02 -2.5946e-02 -4.3996e-02\n",
      " -5.2957e-02  1.6927e-01 -1.7138e-02  ...   1.3861e-01 -6.2269e-02  4.9233e-02\n",
      "     ⋮ \n",
      "\n",
      "(8 ,0 ,.,.) = \n",
      " -4.7283e-03 -7.2364e-02 -5.2149e-02  ...  -2.6725e-03  5.5199e-03  5.7391e-02\n",
      " -3.8792e-02 -5.1054e-02 -7.0401e-02  ...  -7.7504e-04 -1.5164e-02 -9.8726e-02\n",
      " -9.4566e-03 -2.7048e-02 -4.0394e-03  ...   2.2114e-01 -6.6825e-02 -1.1593e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -7.8665e-02  6.0308e-02 -3.3545e-01  ...   1.8427e-01  3.4331e-02 -9.8082e-02\n",
      " -7.5535e-02 -3.1111e-02 -2.9094e-02  ...   3.2684e-02  2.4009e-02 -1.3254e-02\n",
      " -2.8972e-03  1.4390e-01 -4.6683e-02  ...   1.4979e-01 -9.7953e-02 -1.3717e-02\n",
      "     ⋮ \n",
      "\n",
      "(9 ,0 ,.,.) = \n",
      " -6.0719e-02 -6.1312e-02 -3.6919e-02  ...  -3.6062e-02 -1.7560e-02  4.0562e-02\n",
      " -8.5640e-03 -4.1515e-02  2.1923e-02  ...   4.2403e-02  2.6362e-02 -1.0162e-01\n",
      " -1.6569e-02  3.4480e-02 -5.0933e-02  ...   2.2110e-01 -9.4643e-02 -9.0325e-02\n",
      "                 ...                   ⋱                   ...                \n",
      " -5.9592e-03  9.5478e-02 -2.3543e-01  ...   2.1972e-01 -1.7570e-02  3.0027e-02\n",
      " -7.9316e-02  1.7196e-02 -3.1781e-02  ...  -3.5027e-02  5.0262e-03 -1.7309e-02\n",
      " -3.4098e-02  1.1390e-01 -3.4059e-02  ...   2.4971e-01 -1.7381e-01 -1.2349e-02\n",
      "[torch.FloatTensor of size 10x1x28x28]\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-3:\n",
      "Process Process-4:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 35, in _worker_loop\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 378, in get\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 35, in _worker_loop\n",
      "    return recv()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/multiprocessing/queue.py\", line 21, in recv\n",
      "    r = index_queue.get()\n",
      "    buf = self.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Variable containing:\n",
      " 0.1499 -0.4778  0.9060 -0.4313 -0.9350 -0.3977  0.3440  0.5113 -0.6693 -0.0150\n",
      " 0.0748 -0.9997 -0.2833  0.0848 -0.8306 -0.6828  0.2618  0.3055 -0.0795  0.8585\n",
      " 0.8174 -0.2803 -0.8764 -0.6650  0.9967 -0.1577  0.6745  0.8956 -0.7304 -0.9721\n",
      " 0.7480 -0.5349  0.8766  0.4356  0.4382 -0.6811  0.0195 -0.5709 -0.3006  0.5314\n",
      "-0.1940  0.2335  0.2326  0.6668  0.3854  0.9003  0.2779  0.6885  0.4033 -0.0541\n",
      "-0.4044 -0.8425 -0.4944  0.2804  0.7920  0.4238 -0.2951 -0.8358 -0.8103 -0.2369\n",
      "-0.2043  0.7068  0.0413 -0.3494 -0.0759 -0.9432 -0.6595  0.1829 -0.1114  0.9322\n",
      "-0.4580  0.5508 -0.3535 -0.6602 -0.4037 -0.6364  0.0264  0.7172 -0.8352  0.1016\n",
      " 0.9250 -0.1507  0.7303  0.4110  0.5430 -0.8716 -0.7607  0.2870 -0.9677  0.7428\n",
      "-0.2300  0.7895  0.6782  0.8749  0.9842 -0.5989  0.5146  0.3075  0.9180 -0.7334\n",
      "[torch.FloatTensor of size 10x10]\n",
      ", Variable containing:\n",
      " 0.4841 -0.8371\n",
      "-0.2425  0.8418\n",
      " 0.3397  0.0184\n",
      " 1.0742 -0.1434\n",
      "-0.7744  0.9786\n",
      "-0.0042 -0.9155\n",
      " 0.6209 -0.0045\n",
      "-0.6693 -0.3595\n",
      " 0.5652  0.0927\n",
      " 0.3082 -0.1939\n",
      "[torch.FloatTensor of size 10x2]\n",
      ", Variable containing:\n",
      "    0     0     0     0     1     0     0     0     0     0\n",
      "    0     0     0     1     0     0     0     0     0     0\n",
      "    0     0     1     0     0     0     0     0     0     0\n",
      "    0     0     0     1     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     1     0\n",
      "    0     0     0     0     1     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     1     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     1     0     0     0     0     0\n",
      "    0     0     0     1     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 10x10]\n",
      ")\n",
      "('fake_inputs', Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  0.0238 -0.0543 -0.0705  ...   0.0370 -0.0579  0.0525\n",
      "  0.0281 -0.0430 -0.0050  ...   0.0798  0.0108  0.0274\n",
      " -0.0810  0.0179  0.0743  ...   0.0608 -0.0931 -0.1416\n",
      "           ...             ⋱             ...          \n",
      " -0.0490  0.0668 -0.2759  ...   0.1160 -0.0189 -0.0653\n",
      " -0.1284  0.0053 -0.0612  ...  -0.0407  0.0079 -0.0517\n",
      " -0.0825  0.2209 -0.0065  ...   0.1072 -0.0472 -0.0186\n",
      "     ⋮ \n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      " -0.0473 -0.0929 -0.0232  ...  -0.0685 -0.0638  0.0423\n",
      " -0.0377 -0.0905 -0.0654  ...   0.0262 -0.0156 -0.0056\n",
      " -0.1026  0.0334 -0.0206  ...   0.1538 -0.0621 -0.1595\n",
      "           ...             ⋱             ...          \n",
      " -0.0077  0.0307 -0.1835  ...   0.0380 -0.0112 -0.1004\n",
      " -0.1679 -0.0131 -0.0061  ...   0.0245  0.0086 -0.0675\n",
      " -0.0003  0.1839  0.0144  ...   0.2199 -0.0653 -0.0185\n",
      "     ⋮ \n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      " -0.0209 -0.1073 -0.1019  ...   0.0003  0.0060  0.0374\n",
      "  0.0020 -0.0676 -0.0126  ...   0.0108  0.0339 -0.0568\n",
      " -0.0025 -0.0459 -0.0071  ...   0.2807 -0.0722 -0.1434\n",
      "           ...             ⋱             ...          \n",
      " -0.0121  0.1031 -0.1906  ...   0.2434 -0.1154 -0.0662\n",
      " -0.0626 -0.0035 -0.0362  ...   0.0022 -0.0373 -0.0369\n",
      " -0.0574  0.1198  0.0011  ...   0.2394 -0.0591  0.0655\n",
      "...   \n",
      "     ⋮ \n",
      "\n",
      "(7 ,0 ,.,.) = \n",
      " -0.0098 -0.0706 -0.0301  ...  -0.0568 -0.0215  0.0267\n",
      " -0.0058 -0.1289 -0.0263  ...   0.0781 -0.0146 -0.0194\n",
      " -0.0761 -0.0208 -0.0277  ...   0.1190 -0.0641 -0.1341\n",
      "           ...             ⋱             ...          \n",
      " -0.0527  0.0846 -0.2749  ...   0.1551 -0.0609 -0.1081\n",
      " -0.0922  0.0156 -0.0253  ...  -0.0667  0.0090 -0.0324\n",
      " -0.0253  0.1134  0.0321  ...   0.1322 -0.0389 -0.0060\n",
      "     ⋮ \n",
      "\n",
      "(8 ,0 ,.,.) = \n",
      "  0.0592 -0.1378 -0.1060  ...  -0.0261 -0.0319  0.0138\n",
      " -0.0217 -0.0704 -0.1045  ...   0.0647 -0.0343 -0.0093\n",
      "  0.0072  0.0178  0.1000  ...   0.1899 -0.1208 -0.1080\n",
      "           ...             ⋱             ...          \n",
      " -0.0182  0.0215 -0.1589  ...   0.1390 -0.0189 -0.0904\n",
      " -0.1417 -0.0415 -0.0717  ...   0.0265  0.0031  0.0051\n",
      " -0.0674  0.1512 -0.0198  ...   0.0946 -0.1039 -0.0154\n",
      "     ⋮ \n",
      "\n",
      "(9 ,0 ,.,.) = \n",
      " -0.0441 -0.1343 -0.0455  ...  -0.0049  0.0233  0.0542\n",
      " -0.0631 -0.0345 -0.0577  ...   0.0043  0.0554 -0.0458\n",
      " -0.0572 -0.0725  0.0379  ...   0.2933 -0.1331 -0.1144\n",
      "           ...             ⋱             ...          \n",
      " -0.0667  0.0911 -0.2192  ...   0.0749  0.0369 -0.0920\n",
      " -0.1509 -0.0128  0.0131  ...   0.0918 -0.0027  0.0264\n",
      " -0.0804  0.1703 -0.0418  ...   0.1329 -0.0466 -0.0156\n",
      "[torch.FloatTensor of size 10x1x28x28]\n",
      ")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-38bcc91f66a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     run_InfoGAN(n_conti=2, n_discrete=1, D_featmap_dim=64, G_featmap_dim=128,\n\u001b[0;32m--> 152\u001b[0;31m                 n_epoch=1, batch_size=10, update_max=200)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-38bcc91f66a4>\u001b[0m in \u001b[0;36mrun_InfoGAN\u001b[0;34m(info_reg_discrete, info_reg_conti, noise_dim, n_conti, n_discrete, mean, std, num_category, n_layer, n_channel, D_featmap_dim, G_featmap_dim, n_epoch, batch_size, use_gpu, dis_lr, gen_lr, n_update_dis, n_update_gen, update_max)\u001b[0m\n\u001b[1;32m    145\u001b[0m                   \u001b[0mn_conti\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_discrete\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_category\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                   \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                   n_update_dis, n_update_gen, use_gpu, update_max=update_max)\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-38bcc91f66a4>\u001b[0m in \u001b[0;36mtrain_InfoGAN\u001b[0;34m(InfoGAN_Dis, InfoGAN_Gen, D_criterion, G_criterion, D_optimizer, G_optimizer, info_reg_discrete, info_reg_conti, n_conti, n_discrete, mean, std, num_category, trainloader, n_epoch, batch_size, noise_dim, n_update_dis, n_update_gen, use_gpu, print_every, update_max)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn_update_dis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0mD_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0mD_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_variables)\u001b[0m\n\u001b[1;32m    144\u001b[0m                     'or with gradient w.r.t. the variable')\n\u001b[1;32m    145\u001b[0m             \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execution_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_InfoGAN(InfoGAN_Dis, InfoGAN_Gen, D_criterion, G_criterion,\n",
    "                  D_optimizer, G_optimizer, info_reg_discrete, info_reg_conti,\n",
    "                  n_conti, n_discrete, mean, std, num_category, trainloader,\n",
    "                  n_epoch, batch_size, noise_dim,\n",
    "                  n_update_dis=1, n_update_gen=1, use_gpu=False,\n",
    "                  print_every=50, update_max=None):\n",
    "    \"\"\"train InfoGAN and print out the losses for D and G\"\"\"\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "\n",
    "        D_running_loss = 0.0\n",
    "        G_running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs from true distribution\n",
    "            true_inputs, lab = data\n",
    "            true_inputs = Variable(true_inputs)\n",
    "            if use_gpu:\n",
    "                true_inputs = true_inputs.cuda()\n",
    "\n",
    "            # get inputs (noises and codes) for Generator\n",
    "            noises = Variable(gen_noise(batch_size, n_dim=noise_dim))\n",
    "            conti_codes = Variable(gen_conti_codes(batch_size, n_conti,\n",
    "                                                   mean, std))\n",
    "            discr_codes = Variable(gen_discrete_code(batch_size, n_discrete,\n",
    "                                                     num_category))\n",
    "            print (noises, conti_codes, discr_codes)\n",
    "            if use_gpu:\n",
    "                noises = noises.cuda()\n",
    "                conti_codes = conti_codes.cuda()\n",
    "                discr_codes = discr_codes.cuda()\n",
    "                \n",
    "\n",
    "            # generate fake images\n",
    "            gen_inputs = torch.cat((noises, conti_codes, discr_codes), 1)\n",
    "            fake_inputs = InfoGAN_Gen(gen_inputs)\n",
    "            \n",
    "            vutils.save_image(fake_inputs.data, 'fake_inputs.png',nrow=10)\n",
    "            \n",
    "            inputs = torch.cat([true_inputs, fake_inputs])\n",
    "\n",
    "            # make a minibatch of labels\n",
    "            labels = np.zeros(2 * batch_size)\n",
    "            labels[:batch_size] = 1\n",
    "            labels = torch.from_numpy(labels.astype(np.float32))\n",
    "            if use_gpu:\n",
    "                labels = labels.cuda()\n",
    "            labels = Variable(labels)\n",
    "\n",
    "            # Discriminator\n",
    "            D_optimizer.zero_grad()\n",
    "            outputs = InfoGAN_Dis(inputs)\n",
    "\n",
    "            # calculate mutual information lower bound L(G, Q)\n",
    "            for j in range(n_discrete):\n",
    "                shift = (j * num_category)\n",
    "                start = 1 + n_conti + shift\n",
    "                end = start + num_category\n",
    "                Q_cx_discr = outputs[batch_size:, start:end]\n",
    "                codes = discr_codes[:, shift:(shift+num_category)]\n",
    "                condi_entro = -torch.mean(torch.sum(Q_cx_discr * codes, 1))\n",
    "\n",
    "                if j == 0:\n",
    "                    L_discrete = -condi_entro\n",
    "                else:\n",
    "                    L_discrete -= condi_entro\n",
    "            L_discrete /= n_discrete\n",
    "\n",
    "            Q_cx_conti = outputs[batch_size:, 1:(1 + n_conti)]\n",
    "            L_conti = torch.mean(-(((Q_cx_conti - mean) / std) ** 2))\n",
    "\n",
    "            # Update Discriminator\n",
    "            D_loss = D_criterion(outputs[:, 0], labels)\n",
    "            if n_discrete > 0:\n",
    "                D_loss = D_loss - info_reg_discrete * L_discrete\n",
    "\n",
    "            if n_conti > 0:\n",
    "                D_loss = D_loss - info_reg_conti * L_conti\n",
    "\n",
    "            if i % n_update_dis == 0:\n",
    "                D_loss.backward(retain_variables=True)\n",
    "                D_optimizer.step()\n",
    "\n",
    "            # Update Generator\n",
    "            if i % n_update_gen == 0:\n",
    "                G_optimizer.zero_grad()\n",
    "                G_loss = G_criterion(outputs[batch_size:, 0],\n",
    "                                     labels[:batch_size])\n",
    "\n",
    "                if n_discrete > 0:\n",
    "                    G_loss = G_loss - info_reg_discrete * L_discrete\n",
    "\n",
    "                if n_conti > 0:\n",
    "                    G_loss = G_loss - info_reg_conti * L_conti\n",
    "\n",
    "                G_loss.backward()\n",
    "                G_optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            D_running_loss += D_loss.data[0]\n",
    "            G_running_loss += G_loss.data[0]\n",
    "            if i % print_every == (print_every - 1):\n",
    "                print('[%d, %5d] D loss: %.3f ; G loss: %.3f' %\n",
    "                      (epoch+1, i+1, D_running_loss / print_every,\n",
    "                       G_running_loss / print_every))\n",
    "                D_running_loss = 0.0\n",
    "                G_running_loss = 0.0\n",
    "                \n",
    "                _c3_fix = Variable(torch.randn(1,2).cuda().uniform_(-1,1))\n",
    "                for q in range(0,10):\n",
    "                    _c1 = np.zeros((1,10),dtype = np.float32)\n",
    "                    _c1[0,q] = 1\n",
    "                    _c1 = Variable(torch.Tensor(_c1).cuda())\n",
    "                    noise = torch.cat([_c1,_c2_fix,_c3_fix,z_fix],1)\n",
    "                    G_sample = netG(noise)\n",
    "                    storage[k*10+q] = G_sample.data.cpu().numpy()\n",
    "\n",
    "\n",
    "            if update_max and i > update_max:\n",
    "                break\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "def run_InfoGAN(info_reg_discrete=1.0, info_reg_conti=0.5, noise_dim=10,\n",
    "                n_conti=2, n_discrete=1, mean=0.0, std=0.5, num_category=10,\n",
    "                n_layer=3, n_channel=1, D_featmap_dim=256, G_featmap_dim=1024,\n",
    "                n_epoch=2, batch_size=50, use_gpu=False, dis_lr=1e-4,\n",
    "                gen_lr=1e-3, n_update_dis=1, n_update_gen=1, update_max=None):\n",
    "    # loading data\n",
    "    trainloader, testloader = load_dataset(batch_size=batch_size)\n",
    "\n",
    "    # initialize models\n",
    "    InfoGAN_Dis = InfoGAN_Discriminator(n_layer, n_conti, n_discrete,\n",
    "                                        num_category, use_gpu, D_featmap_dim,\n",
    "                                        n_channel)\n",
    "\n",
    "    InfoGAN_Gen = InfoGAN_Generator(noise_dim, n_layer, n_conti, n_discrete,\n",
    "                                    num_category, use_gpu, G_featmap_dim,\n",
    "                                    n_channel)\n",
    "\n",
    "    if use_gpu:\n",
    "        InfoGAN_Dis = InfoGAN_Dis.cuda()\n",
    "        InfoGAN_Gen = InfoGAN_Gen.cuda()\n",
    "\n",
    "    # assign loss function and optimizer (Adam) to D and G\n",
    "    D_criterion = torch.nn.BCELoss()\n",
    "    D_optimizer = optim.Adam(InfoGAN_Dis.parameters(), lr=dis_lr,\n",
    "                             betas=(0.5, 0.999))\n",
    "\n",
    "    G_criterion = torch.nn.BCELoss()\n",
    "    G_optimizer = optim.Adam(InfoGAN_Gen.parameters(), lr=gen_lr,\n",
    "                             betas=(0.5, 0.999))\n",
    "\n",
    "    train_InfoGAN(InfoGAN_Dis, InfoGAN_Gen, D_criterion, G_criterion,\n",
    "                  D_optimizer, G_optimizer, info_reg_discrete, info_reg_conti,\n",
    "                  n_conti, n_discrete, mean, std, num_category, trainloader,\n",
    "                  n_epoch, batch_size, noise_dim,\n",
    "                  n_update_dis, n_update_gen, use_gpu, update_max=update_max)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_InfoGAN(n_conti=2, n_discrete=1, D_featmap_dim=64, G_featmap_dim=128,\n",
    "                n_epoch=1, batch_size=10, update_max=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
