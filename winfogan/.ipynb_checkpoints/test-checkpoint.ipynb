{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(1 * 28 * 28, 256)\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.drop2 = nn.Dropout(p=0.2)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop1(F.leaky_relu(self.fc1(x)))\n",
    "        x = self.drop2(F.leaky_relu(self.fc2(x)))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 512)\n",
    "        self.fc4 = nn.Linear(512, 1 * 28 * 28)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = F.elu(self.fc2(x))\n",
    "        x = F.elu(self.fc3(x))\n",
    "        x = F.tanh(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def sample_c(batchsize,dis,dis_num):\n",
    "    rand_c = np.zeros((batchsize,dis*dis_num),dtype='float32')\n",
    "    label_c = np.zeros((batchsize,dis),dtype='float32')\n",
    "    for i in range(0,batchsize):\n",
    "        rand_dis = np.zeros((dis*dis_num),dtype='float32')\n",
    "        for q in range(0,dis):\n",
    "            rand = np.random.multinomial(1, dis_num*[0.1], size=1)\n",
    "            rand_dis[q*dis_num: q*dis_num+dis_num] = rand\n",
    "            label_c[i,q] = np.argmax(rand)\n",
    "        rand_c[i] = rand_dis\n",
    "    \n",
    "    label_c = label_c.reshape(batchsize,dis,1)\n",
    "    label_c = torch.LongTensor(label_c.astype('int'))\n",
    "    rand_c = torch.from_numpy(rand_c.astype('float32'))\n",
    "    return rand_c,label_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_c(batchsize,dis_code,dis):\n",
    "    label_rand = np.random.randint(0, dis_code, [batchsize,dis,1])\n",
    "    dis_rand = np.zeros((batchsize,dis_code, dis,1),dtype='float32')\n",
    "    for i in range(batchsize):\n",
    "        for j in range(dis):\n",
    "            dis_rand[i, label_rand[i,j], j, 0] = 1\n",
    "    return dis_rand, label_rand\n",
    "\n",
    "dis_rand, label_rand = sample_c(64, 20, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-1\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_logli = nn.NLLLoss2d()\n",
    "a = Variable(torch.FloatTensor(dis_rand))\n",
    "b = Variable(torch.LongTensor(label_rand))\n",
    "criterion_logli(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.2000\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.from_numpy(np.array([0.2,0.2,0.2,0.2,0.2],dtype=np.float32))\n",
    "b = torch.LongTensor(np.array([2],dtype=int))\n",
    "a = Variable(a.view(1,5))\n",
    "b = Variable(b.view(1))\n",
    "criterion_logli = nn.NLLLoss()\n",
    "criterion_logli(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _netD_D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_netD_D, self).__init__()\n",
    "        self.conv = nn.Conv2d(256, 1, 4, 1, 0, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "class _netD_Q(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_netD_Q, self).__init__()\n",
    "        # input is Z, going into a convolution\n",
    "        self.conv = self.conv2 = self.conv3 = self.conv4 = self.conv5 =  nn.Conv2d(256, 20, 4, 1, 0, bias=False)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv(x)\n",
    "        x2 = self.conv2(x)\n",
    "        x3 = self.conv3(x)\n",
    "        x4 = self.conv4(x)\n",
    "        x5 = self.conv5(x)\n",
    "        \n",
    "        x1 = self.softmax(x1)\n",
    "        x2 = self.softmax(x2)\n",
    "        x3 = self.softmax(x3)\n",
    "        x4 = self.softmax(x4)\n",
    "        x5 = self.softmax(x5)\n",
    "        \n",
    "        x = torch.cat([x1,x2,x3,x4,x5],2)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class _netD_Q_3(nn.Module):\n",
    "    def __init__(self, nc = 4):\n",
    "        super(_netD_Q_3, self).__init__()\n",
    "        # input is Z, going into a convolution\n",
    "        self.conv = nn.Conv2d(256, nc, 4, 1, 0, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "netD_D = _netD_D()\n",
    "netD_Q = _netD_Q()\n",
    "netD_Q_3 = _netD_Q_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,0 ,.,.) = \n",
       " -4.1040\n",
       " -4.1040\n",
       " -4.1040\n",
       " -4.1040\n",
       " -4.1040\n",
       "\n",
       "(0 ,1 ,.,.) = \n",
       " -2.8563\n",
       " -2.8563\n",
       " -2.8563\n",
       " -2.8563\n",
       " -2.8563\n",
       "\n",
       "(0 ,2 ,.,.) = \n",
       " -2.8347\n",
       " -2.8347\n",
       " -2.8347\n",
       " -2.8347\n",
       " -2.8347\n",
       "   ...\n",
       "\n",
       "(0 ,17,.,.) = \n",
       " -2.7579\n",
       " -2.7579\n",
       " -2.7579\n",
       " -2.7579\n",
       " -2.7579\n",
       "\n",
       "(0 ,18,.,.) = \n",
       " -2.8392\n",
       " -2.8392\n",
       " -2.8392\n",
       " -2.8392\n",
       " -2.8392\n",
       "\n",
       "(0 ,19,.,.) = \n",
       " -3.1612\n",
       " -3.1612\n",
       " -3.1612\n",
       " -3.1612\n",
       " -3.1612\n",
       "     ⋮ \n",
       "\n",
       "(1 ,0 ,.,.) = \n",
       " -3.9687\n",
       " -3.9687\n",
       " -3.9687\n",
       " -3.9687\n",
       " -3.9687\n",
       "\n",
       "(1 ,1 ,.,.) = \n",
       " -2.1187\n",
       " -2.1187\n",
       " -2.1187\n",
       " -2.1187\n",
       " -2.1187\n",
       "\n",
       "(1 ,2 ,.,.) = \n",
       " -3.1607\n",
       " -3.1607\n",
       " -3.1607\n",
       " -3.1607\n",
       " -3.1607\n",
       "   ...\n",
       "\n",
       "(1 ,17,.,.) = \n",
       " -2.0770\n",
       " -2.0770\n",
       " -2.0770\n",
       " -2.0770\n",
       " -2.0770\n",
       "\n",
       "(1 ,18,.,.) = \n",
       " -3.6605\n",
       " -3.6605\n",
       " -3.6605\n",
       " -3.6605\n",
       " -3.6605\n",
       "\n",
       "(1 ,19,.,.) = \n",
       " -2.9146\n",
       " -2.9146\n",
       " -2.9146\n",
       " -2.9146\n",
       " -2.9146\n",
       "     ⋮ \n",
       "\n",
       "(2 ,0 ,.,.) = \n",
       " -3.7098\n",
       " -3.7098\n",
       " -3.7098\n",
       " -3.7098\n",
       " -3.7098\n",
       "\n",
       "(2 ,1 ,.,.) = \n",
       " -2.8350\n",
       " -2.8350\n",
       " -2.8350\n",
       " -2.8350\n",
       " -2.8350\n",
       "\n",
       "(2 ,2 ,.,.) = \n",
       " -3.4972\n",
       " -3.4972\n",
       " -3.4972\n",
       " -3.4972\n",
       " -3.4972\n",
       "   ...\n",
       "\n",
       "(2 ,17,.,.) = \n",
       " -3.5979\n",
       " -3.5979\n",
       " -3.5979\n",
       " -3.5979\n",
       " -3.5979\n",
       "\n",
       "(2 ,18,.,.) = \n",
       " -2.1750\n",
       " -2.1750\n",
       " -2.1750\n",
       " -2.1750\n",
       " -2.1750\n",
       "\n",
       "(2 ,19,.,.) = \n",
       " -3.5961\n",
       " -3.5961\n",
       " -3.5961\n",
       " -3.5961\n",
       " -3.5961\n",
       "...   \n",
       "     ⋮ \n",
       "\n",
       "(61,0 ,.,.) = \n",
       " -4.3463\n",
       " -4.3463\n",
       " -4.3463\n",
       " -4.3463\n",
       " -4.3463\n",
       "\n",
       "(61,1 ,.,.) = \n",
       " -2.8093\n",
       " -2.8093\n",
       " -2.8093\n",
       " -2.8093\n",
       " -2.8093\n",
       "\n",
       "(61,2 ,.,.) = \n",
       " -2.5958\n",
       " -2.5958\n",
       " -2.5958\n",
       " -2.5958\n",
       " -2.5958\n",
       "   ...\n",
       "\n",
       "(61,17,.,.) = \n",
       " -2.4975\n",
       " -2.4975\n",
       " -2.4975\n",
       " -2.4975\n",
       " -2.4975\n",
       "\n",
       "(61,18,.,.) = \n",
       " -4.6388\n",
       " -4.6388\n",
       " -4.6388\n",
       " -4.6388\n",
       " -4.6388\n",
       "\n",
       "(61,19,.,.) = \n",
       " -3.0545\n",
       " -3.0545\n",
       " -3.0545\n",
       " -3.0545\n",
       " -3.0545\n",
       "     ⋮ \n",
       "\n",
       "(62,0 ,.,.) = \n",
       " -3.3567\n",
       " -3.3567\n",
       " -3.3567\n",
       " -3.3567\n",
       " -3.3567\n",
       "\n",
       "(62,1 ,.,.) = \n",
       " -3.2395\n",
       " -3.2395\n",
       " -3.2395\n",
       " -3.2395\n",
       " -3.2395\n",
       "\n",
       "(62,2 ,.,.) = \n",
       " -2.8194\n",
       " -2.8194\n",
       " -2.8194\n",
       " -2.8194\n",
       " -2.8194\n",
       "   ...\n",
       "\n",
       "(62,17,.,.) = \n",
       " -3.2342\n",
       " -3.2342\n",
       " -3.2342\n",
       " -3.2342\n",
       " -3.2342\n",
       "\n",
       "(62,18,.,.) = \n",
       " -2.3904\n",
       " -2.3904\n",
       " -2.3904\n",
       " -2.3904\n",
       " -2.3904\n",
       "\n",
       "(62,19,.,.) = \n",
       " -2.1410\n",
       " -2.1410\n",
       " -2.1410\n",
       " -2.1410\n",
       " -2.1410\n",
       "     ⋮ \n",
       "\n",
       "(63,0 ,.,.) = \n",
       " -3.3611\n",
       " -3.3611\n",
       " -3.3611\n",
       " -3.3611\n",
       " -3.3611\n",
       "\n",
       "(63,1 ,.,.) = \n",
       " -2.8315\n",
       " -2.8315\n",
       " -2.8315\n",
       " -2.8315\n",
       " -2.8315\n",
       "\n",
       "(63,2 ,.,.) = \n",
       " -2.5964\n",
       " -2.5964\n",
       " -2.5964\n",
       " -2.5964\n",
       " -2.5964\n",
       "   ...\n",
       "\n",
       "(63,17,.,.) = \n",
       " -3.4635\n",
       " -3.4635\n",
       " -3.4635\n",
       " -3.4635\n",
       " -3.4635\n",
       "\n",
       "(63,18,.,.) = \n",
       " -2.8699\n",
       " -2.8699\n",
       " -2.8699\n",
       " -2.8699\n",
       " -2.8699\n",
       "\n",
       "(63,19,.,.) = \n",
       " -3.6637\n",
       " -3.6637\n",
       " -3.6637\n",
       " -3.6637\n",
       " -3.6637\n",
       "[torch.FloatTensor of size 64x20x5x1]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netD_Q(Variable(torch.randn(64,256,4,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.from_numpy(np.array([0,1,0,0,0,0]*9,dtype=np.float32))\n",
    "b = torch.LongTensor(np.array([1]*9,dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-1\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_logli = nn.NLLLoss2d(size_average=False)\n",
    "a = Variable(a.view(1,6,9,1))\n",
    "b = Variable(b.view(1,9,1))\n",
    "criterion_logli(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_rand = np.random.randint(0, 20, [64,5])\n",
    "dis_rand = np.zeros((64,20*5),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dis_rand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Author: aaronlai\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def load_dataset(batch_size=10, download=True):\n",
    "    \"\"\"\n",
    "    The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "    Transform them to Tensors of normalized range [-1, 1]\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                         (0.5, 0.5, 0.5))])\n",
    "    trainset = torchvision.datasets.MNIST(root='../data', train=True,\n",
    "                                          download=download,\n",
    "                                          transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.MNIST(root='../data', train=False,\n",
    "                                         download=download,\n",
    "                                         transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                             shuffle=False, num_workers=2)\n",
    "\n",
    "    return trainloader, testloader\n",
    "\n",
    "\n",
    "def gen_noise(n_instance):\n",
    "    \"\"\"generate n-dim uniform random noise\"\"\"\n",
    "    return torch.Tensor(np.random.uniform(low=-1.0, high=1.0,\n",
    "                                          size=(n_instance, 2)))\n",
    "\n",
    "\n",
    "def train_GAN(Dis_model, Gen_model, D_criterion, G_criterion, D_optimizer,\n",
    "              G_optimizer, trainloader, n_epoch, batch_size,\n",
    "              n_update_dis=1, n_update_gen=1, use_gpu=False, print_every=10,\n",
    "              update_max=None):\n",
    "    \"\"\"train GAN and print out the losses for D and G\"\"\"\n",
    "    for epoch in range(n_epoch):\n",
    "\n",
    "        D_running_loss = 0.0\n",
    "        G_running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs from true distribution\n",
    "            true_inputs, _ = data\n",
    "            true_inputs = true_inputs.view(-1, 1 * 28 * 28)\n",
    "            if use_gpu:\n",
    "                true_inputs = true_inputs.cuda()\n",
    "            true_inputs = Variable(true_inputs)\n",
    "\n",
    "            # get the inputs from the generator\n",
    "            noises = gen_noise(batch_size)\n",
    "            if use_gpu:\n",
    "                noises = noises.cuda()\n",
    "            fake_inputs = Gen_model(Variable(noises))\n",
    "            print (fake_inputs)\n",
    "            inputs = torch.cat([true_inputs, fake_inputs])\n",
    "\n",
    "            # get the labels\n",
    "            labels = np.zeros(2 * batch_size)\n",
    "            labels[:batch_size] = 1\n",
    "            labels = torch.from_numpy(labels.astype(np.float32))\n",
    "            if use_gpu:\n",
    "                labels = labels.cuda()\n",
    "            labels = Variable(labels)\n",
    "\n",
    "            # Discriminator\n",
    "            D_optimizer.zero_grad()\n",
    "            outputs = Dis_model(inputs)\n",
    "            D_loss = D_criterion(outputs[:, 0], labels)\n",
    "            if i % n_update_dis == 0:\n",
    "                D_loss.backward(retain_variables=True)\n",
    "                D_optimizer.step()\n",
    "\n",
    "            # Generator\n",
    "            if i % n_update_gen == 0:\n",
    "                G_optimizer.zero_grad()\n",
    "                G_loss = G_criterion(outputs[batch_size:, 0],\n",
    "                                     labels[:batch_size])\n",
    "                G_loss.backward()\n",
    "                G_optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            D_running_loss += D_loss.data[0]\n",
    "            G_running_loss += G_loss.data[0]\n",
    "            if i % print_every == (print_every - 1):\n",
    "                print('[%d, %5d] D loss: %.3f ; G loss: %.3f' %\n",
    "                      (epoch+1, i+1, D_running_loss / print_every,\n",
    "                       G_running_loss / print_every))\n",
    "                D_running_loss = 0.0\n",
    "                G_running_loss = 0.0\n",
    "                vutils.save_image(fake_inputs, 'img.png',nrow=10)\n",
    "            if update_max and i > update_max:\n",
    "                break\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "def run_GAN(n_epoch=2, batch_size=50, use_gpu=False, dis_lr=1e-4, gen_lr=1e-3,\n",
    "            n_update_dis=1, n_update_gen=1, update_max=None):\n",
    "    # loading data\n",
    "    trainloader, testloader = load_dataset(batch_size=batch_size)\n",
    "\n",
    "    # initialize models\n",
    "    Dis_model = Discriminator()\n",
    "    Gen_model = Generator()\n",
    "\n",
    "    if use_gpu:\n",
    "        Dis_model = Dis_model.cuda()\n",
    "        Gen_model = Gen_model.cuda()\n",
    "\n",
    "    # assign loss function and optimizer to D and G\n",
    "    D_criterion = torch.nn.BCELoss()\n",
    "    D_optimizer = optim.SGD(Dis_model.parameters(), lr=dis_lr, momentum=0.9)\n",
    "\n",
    "    G_criterion = torch.nn.BCELoss()\n",
    "    G_optimizer = optim.SGD(Gen_model.parameters(), lr=gen_lr, momentum=0.9)\n",
    "\n",
    "    train_GAN(Dis_model, Gen_model, D_criterion, G_criterion, D_optimizer,\n",
    "              G_optimizer, trainloader, n_epoch, batch_size, n_update_dis,\n",
    "              n_update_gen, update_max=update_max)\n",
    "    \n",
    "   \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    run_GAN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fake_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "array1 = torch.from_numpy(np.array([[1,2,3,4]],dtype=np.float32)).cuda()\n",
    "array2 = torch.from_numpy(np.array([[2,1,2,3]],dtype=np.float32)).cuda()\n",
    "(array1 - array2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
