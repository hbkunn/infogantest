{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Author: aaronlai\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class InfoGAN_Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, n_layer=3, n_conti=2, n_discrete=1,\n",
    "                 num_category=10, use_gpu=False, featmap_dim=256,\n",
    "                 n_channel=1):\n",
    "        \"\"\"\n",
    "        InfoGAN Discriminator, have additional outputs for latent codes.\n",
    "        Architecture brought from DCGAN.\n",
    "        \"\"\"\n",
    "        super(InfoGAN_Discriminator, self).__init__()\n",
    "        self.n_layer = n_layer\n",
    "        self.n_conti = n_conti\n",
    "        self.n_discrete = n_discrete\n",
    "        self.num_category = num_category\n",
    "\n",
    "        # Discriminator\n",
    "        self.featmap_dim = featmap_dim\n",
    "\n",
    "        convs = []\n",
    "        BNs = []\n",
    "        for layer in range(self.n_layer):\n",
    "            if layer == (self.n_layer - 1):\n",
    "                n_conv_in = n_channel\n",
    "            else:\n",
    "                n_conv_in = int(featmap_dim / (2**(layer + 1)))\n",
    "            n_conv_out = int(featmap_dim / (2**layer))\n",
    "\n",
    "            _conv = nn.Conv2d(n_conv_in, n_conv_out, kernel_size=5,\n",
    "                              stride=2, padding=2)\n",
    "            if use_gpu:\n",
    "                _conv = _conv.cuda()\n",
    "            convs.append(_conv)\n",
    "\n",
    "            if layer != (self.n_layer - 1):\n",
    "                _BN = nn.BatchNorm2d(n_conv_out)\n",
    "                if use_gpu:\n",
    "                    _BN = _BN.cuda()\n",
    "                BNs.append(_BN)\n",
    "\n",
    "        # output layer - prob(real) and auxiliary distributions Q(c_j|x)\n",
    "        n_hidden = featmap_dim * 4 * 4\n",
    "        n_output = 1 + n_conti + n_discrete * num_category\n",
    "        self.fc = nn.Linear(n_hidden, n_output)\n",
    "\n",
    "        # register all nn modules\n",
    "        self.convs = nn.ModuleList(convs)\n",
    "        self.BNs = nn.ModuleList(BNs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Output the probability of being in real dataset\n",
    "        plus the conditional distributions of latent codes.\n",
    "        \"\"\"\n",
    "        for layer in range(self.n_layer):\n",
    "            conv_layer = self.convs[self.n_layer - layer - 1]\n",
    "\n",
    "            if layer == 0:\n",
    "                x = F.leaky_relu(conv_layer(x), negative_slope=0.2)\n",
    "            else:\n",
    "                BN_layer = self.BNs[self.n_layer - layer - 1]\n",
    "                x = F.leaky_relu(BN_layer(conv_layer(x)), negative_slope=0.2)\n",
    "\n",
    "        x = x.view(-1, self.featmap_dim * 4 * 4)\n",
    "\n",
    "        # output layer\n",
    "        x = self.fc(x)\n",
    "        x[:, 0] = F.sigmoid(x[:, 0].clone())\n",
    "        for j in range(self.n_discrete):\n",
    "            start = 1 + self.n_conti + j * self.num_category\n",
    "            end = start + self.num_category\n",
    "            x[:, start:end] = F.softmax(x[:, start:end].clone())\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class InfoGAN_Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, noise_dim=10, n_layer=3, n_conti=2, n_discrete=1,\n",
    "                 num_category=10, use_gpu=False, featmap_dim=256, n_channel=1):\n",
    "        \"\"\"\n",
    "        InfoGAN Generator, have an additional input branch for latent codes.\n",
    "        Architecture brought from DCGAN.\n",
    "        \"\"\"\n",
    "        super(InfoGAN_Generator, self).__init__()\n",
    "        self.n_layer = n_layer\n",
    "        self.n_conti = n_conti\n",
    "        self.n_discrete = n_discrete\n",
    "        self.num_category = num_category\n",
    "\n",
    "        # calculate input dimension\n",
    "        n_input = noise_dim + n_conti + n_discrete * num_category\n",
    "\n",
    "        # Generator\n",
    "        self.featmap_dim = featmap_dim\n",
    "        self.fc_in = nn.Linear(n_input, featmap_dim * 4 * 4)\n",
    "\n",
    "        convs = []\n",
    "        BNs = []\n",
    "        for layer in range(self.n_layer):\n",
    "            if layer == 0:\n",
    "                n_conv_out = n_channel\n",
    "            else:\n",
    "                n_conv_out = featmap_dim / (2 ** (self.n_layer - layer))\n",
    "\n",
    "            n_conv_in = featmap_dim / (2 ** (self.n_layer - layer - 1))\n",
    "            n_width = 5 if layer == (self.n_layer - 1) else 6\n",
    "\n",
    "            _conv = nn.ConvTranspose2d(n_conv_in, n_conv_out, n_width,\n",
    "                                       stride=2, padding=2)\n",
    "\n",
    "            if use_gpu:\n",
    "                _conv = _conv.cuda()\n",
    "            convs.append(_conv)\n",
    "\n",
    "            if layer != 0:\n",
    "                _BN = nn.BatchNorm2d(n_conv_out)\n",
    "                if use_gpu:\n",
    "                    _BN = _BN.cuda()\n",
    "                BNs.append(_BN)\n",
    "\n",
    "        # register all nn modules\n",
    "        self.convs = nn.ModuleList(convs)\n",
    "        self.BNs = nn.ModuleList(BNs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input the random noise plus latent codes to generate fake images.\n",
    "        \"\"\"\n",
    "        x = self.fc_in(x)\n",
    "        x = x.view(-1, self.featmap_dim, 4, 4)\n",
    "\n",
    "        for layer in range(self.n_layer):\n",
    "            conv_layer = self.convs[self.n_layer - layer - 1]\n",
    "            if layer == (self.n_layer - 1):\n",
    "                x = F.tanh(conv_layer(x))\n",
    "            else:\n",
    "                BN_layer = self.BNs[self.n_layer - layer - 2]\n",
    "                x = F.relu(BN_layer(conv_layer(x)))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    50] D loss: 0.633 ; G loss: 0.344\n",
      "[1,   100] D loss: 0.532 ; G loss: 0.480\n",
      "[1,   150] D loss: 0.575 ; G loss: 0.587\n",
      "[1,   200] D loss: 0.571 ; G loss: 0.631\n",
      "[1,   250] D loss: 0.586 ; G loss: 0.607\n",
      "[1,   300] D loss: 0.581 ; G loss: 0.598\n",
      "[1,   350] D loss: 0.575 ; G loss: 0.674\n",
      "[1,   400] D loss: 0.601 ; G loss: 0.565\n",
      "[1,   450] D loss: 0.584 ; G loss: 0.586\n",
      "[1,   500] D loss: 0.522 ; G loss: 0.703\n",
      "[1,   550] D loss: 0.574 ; G loss: 0.639\n",
      "[1,   600] D loss: 0.495 ; G loss: 0.711\n",
      "[1,   650] D loss: 0.565 ; G loss: 0.586\n",
      "[1,   700] D loss: 0.523 ; G loss: 0.724\n",
      "[1,   750] D loss: 0.550 ; G loss: 0.657\n",
      "[1,   800] D loss: 0.546 ; G loss: 0.707\n",
      "[1,   850] D loss: 0.508 ; G loss: 0.670\n",
      "[1,   900] D loss: 0.537 ; G loss: 0.642\n",
      "[1,   950] D loss: 0.547 ; G loss: 0.668\n",
      "[1,  1000] D loss: 0.404 ; G loss: 0.909\n",
      "[1,  1050] D loss: 0.364 ; G loss: 0.889\n",
      "[1,  1100] D loss: 0.490 ; G loss: 0.796\n",
      "[1,  1150] D loss: 0.380 ; G loss: 0.878\n",
      "[1,  1200] D loss: 0.439 ; G loss: 0.790\n",
      "[1,  1250] D loss: 0.526 ; G loss: 0.655\n",
      "[1,  1300] D loss: 0.398 ; G loss: 0.916\n",
      "[1,  1350] D loss: 0.464 ; G loss: 0.804\n",
      "[1,  1400] D loss: 0.401 ; G loss: 0.943\n",
      "[1,  1450] D loss: 0.393 ; G loss: 0.912\n",
      "[1,  1500] D loss: 0.460 ; G loss: 0.790\n",
      "[1,  1550] D loss: 0.325 ; G loss: 0.858\n",
      "[1,  1600] D loss: 0.229 ; G loss: 0.992\n",
      "[1,  1650] D loss: 0.321 ; G loss: 0.873\n",
      "[1,  1700] D loss: 0.144 ; G loss: 1.402\n",
      "[1,  1750] D loss: 0.181 ; G loss: 1.014\n",
      "[1,  1800] D loss: 0.219 ; G loss: 1.040\n",
      "[1,  1850] D loss: 0.186 ; G loss: 1.010\n",
      "[1,  1900] D loss: 0.285 ; G loss: 0.952\n",
      "[1,  1950] D loss: 0.195 ; G loss: 1.089\n",
      "[1,  2000] D loss: 0.259 ; G loss: 0.921\n",
      "[1,  2050] D loss: 0.174 ; G loss: 1.116\n",
      "[1,  2100] D loss: 0.277 ; G loss: 0.933\n",
      "[1,  2150] D loss: 0.279 ; G loss: 0.665\n",
      "[1,  2200] D loss: 0.317 ; G loss: 0.648\n",
      "[1,  2250] D loss: 0.143 ; G loss: 0.702\n",
      "[1,  2300] D loss: 0.310 ; G loss: 0.609\n",
      "[1,  2350] D loss: 0.133 ; G loss: 0.680\n",
      "[1,  2400] D loss: 0.219 ; G loss: 0.516\n",
      "[1,  2450] D loss: 0.099 ; G loss: 0.688\n",
      "[1,  2500] D loss: 0.036 ; G loss: 0.721\n",
      "[1,  2550] D loss: 0.038 ; G loss: 0.754\n",
      "[1,  2600] D loss: 0.168 ; G loss: 0.511\n",
      "[1,  2650] D loss: 0.002 ; G loss: 0.680\n",
      "[1,  2700] D loss: -0.023 ; G loss: 0.598\n",
      "[1,  2750] D loss: -0.036 ; G loss: 0.791\n",
      "[1,  2800] D loss: -0.087 ; G loss: 0.558\n",
      "[1,  2850] D loss: -0.001 ; G loss: 0.649\n",
      "[1,  2900] D loss: -0.048 ; G loss: 0.548\n",
      "[1,  2950] D loss: -0.089 ; G loss: 0.420\n",
      "[1,  3000] D loss: 0.018 ; G loss: 0.361\n",
      "[1,  3050] D loss: -0.120 ; G loss: 0.302\n",
      "[1,  3100] D loss: -0.131 ; G loss: 0.189\n",
      "[1,  3150] D loss: -0.162 ; G loss: 0.020\n",
      "[1,  3200] D loss: -0.238 ; G loss: -0.065\n",
      "[1,  3250] D loss: -0.311 ; G loss: -0.100\n",
      "[1,  3300] D loss: -0.351 ; G loss: -0.087\n",
      "[1,  3350] D loss: -0.345 ; G loss: -0.124\n",
      "[1,  3400] D loss: -0.325 ; G loss: -0.136\n",
      "[1,  3450] D loss: -0.324 ; G loss: -0.142\n",
      "[1,  3500] D loss: -0.333 ; G loss: -0.165\n",
      "[1,  3550] D loss: -0.357 ; G loss: -0.118\n",
      "[1,  3600] D loss: -0.300 ; G loss: -0.157\n",
      "[1,  3650] D loss: -0.298 ; G loss: -0.166\n",
      "[1,  3700] D loss: -0.298 ; G loss: -0.192\n",
      "[1,  3750] D loss: -0.306 ; G loss: -0.200\n",
      "[1,  3800] D loss: -0.352 ; G loss: -0.172\n",
      "[1,  3850] D loss: -0.368 ; G loss: -0.130\n",
      "[1,  3900] D loss: -0.371 ; G loss: -0.155\n",
      "[1,  3950] D loss: -0.350 ; G loss: -0.156\n",
      "[1,  4000] D loss: -0.336 ; G loss: -0.166\n",
      "[1,  4050] D loss: -0.346 ; G loss: -0.162\n",
      "[1,  4100] D loss: -0.341 ; G loss: -0.167\n",
      "[1,  4150] D loss: -0.324 ; G loss: -0.182\n",
      "[1,  4200] D loss: -0.331 ; G loss: -0.176\n",
      "[1,  4250] D loss: -0.336 ; G loss: -0.171\n",
      "[1,  4300] D loss: -0.352 ; G loss: -0.188\n",
      "[1,  4350] D loss: -0.359 ; G loss: -0.144\n",
      "[1,  4400] D loss: -0.370 ; G loss: -0.150\n",
      "[1,  4450] D loss: -0.392 ; G loss: -0.120\n",
      "[1,  4500] D loss: -0.344 ; G loss: -0.169\n",
      "[1,  4550] D loss: -0.320 ; G loss: -0.177\n",
      "[1,  4600] D loss: -0.312 ; G loss: -0.191\n",
      "[1,  4650] D loss: -0.351 ; G loss: -0.172\n",
      "[1,  4700] D loss: -0.340 ; G loss: -0.183\n",
      "[1,  4750] D loss: -0.339 ; G loss: -0.188\n",
      "[1,  4800] D loss: -0.325 ; G loss: -0.191\n",
      "[1,  4850] D loss: -0.337 ; G loss: -0.191\n",
      "[1,  4900] D loss: -0.348 ; G loss: -0.157\n",
      "[1,  4950] D loss: -0.365 ; G loss: -0.161\n",
      "[1,  5000] D loss: -0.350 ; G loss: -0.181\n",
      "[1,  5050] D loss: -0.365 ; G loss: -0.142\n",
      "[1,  5100] D loss: -0.386 ; G loss: -0.101\n",
      "[1,  5150] D loss: -0.353 ; G loss: -0.132\n",
      "[1,  5200] D loss: -0.358 ; G loss: -0.122\n",
      "[1,  5250] D loss: -0.376 ; G loss: -0.146\n",
      "[1,  5300] D loss: -0.394 ; G loss: -0.119\n",
      "[1,  5350] D loss: -0.365 ; G loss: -0.147\n",
      "[1,  5400] D loss: -0.377 ; G loss: -0.119\n",
      "[1,  5450] D loss: -0.340 ; G loss: -0.185\n",
      "[1,  5500] D loss: -0.330 ; G loss: -0.201\n",
      "[1,  5550] D loss: -0.325 ; G loss: -0.184\n",
      "[1,  5600] D loss: -0.342 ; G loss: -0.193\n",
      "[1,  5650] D loss: -0.328 ; G loss: -0.218\n",
      "[1,  5700] D loss: -0.357 ; G loss: -0.171\n",
      "[1,  5750] D loss: -0.375 ; G loss: -0.154\n",
      "[1,  5800] D loss: -0.361 ; G loss: -0.178\n",
      "[1,  5850] D loss: -0.354 ; G loss: -0.170\n",
      "[1,  5900] D loss: -0.346 ; G loss: -0.191\n",
      "[1,  5950] D loss: -0.358 ; G loss: -0.166\n",
      "[1,  6000] D loss: -0.358 ; G loss: -0.140\n",
      "[2,    50] D loss: -0.338 ; G loss: -0.181\n",
      "[2,   100] D loss: -0.342 ; G loss: -0.186\n",
      "[2,   150] D loss: -0.375 ; G loss: -0.138\n",
      "[2,   200] D loss: -0.376 ; G loss: -0.133\n",
      "[2,   250] D loss: -0.354 ; G loss: -0.167\n",
      "[2,   300] D loss: -0.349 ; G loss: -0.165\n",
      "[2,   350] D loss: -0.309 ; G loss: -0.202\n",
      "[2,   400] D loss: -0.364 ; G loss: -0.173\n",
      "[2,   450] D loss: -0.372 ; G loss: -0.151\n",
      "[2,   500] D loss: -0.328 ; G loss: -0.175\n",
      "[2,   550] D loss: -0.342 ; G loss: -0.177\n",
      "[2,   600] D loss: -0.333 ; G loss: -0.178\n",
      "[2,   650] D loss: -0.354 ; G loss: -0.166\n",
      "[2,   700] D loss: -0.365 ; G loss: -0.169\n",
      "[2,   750] D loss: -0.363 ; G loss: -0.156\n",
      "[2,   800] D loss: -0.348 ; G loss: -0.176\n",
      "[2,   850] D loss: -0.375 ; G loss: -0.148\n",
      "[2,   900] D loss: -0.333 ; G loss: -0.198\n",
      "[2,   950] D loss: -0.398 ; G loss: -0.155\n",
      "[2,  1000] D loss: -0.350 ; G loss: -0.154\n",
      "[2,  1050] D loss: -0.337 ; G loss: -0.193\n",
      "[2,  1100] D loss: -0.315 ; G loss: -0.203\n",
      "[2,  1150] D loss: -0.365 ; G loss: -0.149\n",
      "[2,  1200] D loss: -0.369 ; G loss: -0.173\n",
      "[2,  1250] D loss: -0.364 ; G loss: -0.166\n",
      "[2,  1300] D loss: -0.385 ; G loss: -0.159\n",
      "[2,  1350] D loss: -0.389 ; G loss: -0.139\n",
      "[2,  1400] D loss: -0.384 ; G loss: -0.122\n",
      "[2,  1450] D loss: -0.399 ; G loss: -0.114\n",
      "[2,  1500] D loss: -0.374 ; G loss: -0.134\n",
      "[2,  1550] D loss: -0.412 ; G loss: -0.101\n",
      "[2,  1600] D loss: -0.385 ; G loss: -0.124\n",
      "[2,  1650] D loss: -0.392 ; G loss: -0.117\n",
      "[2,  1700] D loss: -0.357 ; G loss: -0.168\n",
      "[2,  1750] D loss: -0.357 ; G loss: -0.162\n",
      "[2,  1800] D loss: -0.355 ; G loss: -0.160\n",
      "[2,  1850] D loss: -0.355 ; G loss: -0.183\n",
      "[2,  1900] D loss: -0.358 ; G loss: -0.156\n",
      "[2,  1950] D loss: -0.376 ; G loss: -0.123\n",
      "[2,  2000] D loss: -0.335 ; G loss: -0.195\n",
      "[2,  2050] D loss: -0.372 ; G loss: -0.145\n",
      "[2,  2100] D loss: -0.395 ; G loss: -0.074\n",
      "[2,  2150] D loss: -0.386 ; G loss: -0.135\n",
      "[2,  2200] D loss: -0.381 ; G loss: -0.100\n",
      "[2,  2250] D loss: -0.368 ; G loss: -0.139\n",
      "[2,  2300] D loss: -0.412 ; G loss: -0.090\n",
      "[2,  2350] D loss: -0.415 ; G loss: -0.107\n",
      "[2,  2400] D loss: -0.363 ; G loss: -0.154\n",
      "[2,  2450] D loss: -0.333 ; G loss: -0.189\n",
      "[2,  2500] D loss: -0.357 ; G loss: -0.160\n",
      "[2,  2550] D loss: -0.309 ; G loss: -0.218\n",
      "[2,  2600] D loss: -0.355 ; G loss: -0.173\n",
      "[2,  2650] D loss: -0.377 ; G loss: -0.133\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Author: aaronlai\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def load_dataset(batch_size=10, download=True):\n",
    "    \"\"\"\n",
    "    The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "    Transform them to Tensors of normalized range [-1, 1]\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                         (0.5, 0.5, 0.5))])\n",
    "    trainset = torchvision.datasets.MNIST(root='../data', train=True,\n",
    "                                          download=download,\n",
    "                                          transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.MNIST(root='../data', train=False,\n",
    "                                         download=download,\n",
    "                                         transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                             shuffle=False, num_workers=2)\n",
    "\n",
    "    return trainloader, testloader\n",
    "\n",
    "\n",
    "def gen_noise(n_instance, n_dim=2):\n",
    "    \"\"\"generate n-dim uniform random noise\"\"\"\n",
    "    return torch.Tensor(np.random.uniform(low=-1.0, high=1.0,\n",
    "                                          size=(n_instance, n_dim)))\n",
    "\n",
    "\n",
    "def gen_conti_codes(n_instance, n_conti, mean=0, std=1):\n",
    "    \"\"\"generate gaussian continuous codes with specified mean and std\"\"\"\n",
    "    codes = np.random.randn(n_instance, n_conti) * std + mean\n",
    "    return torch.Tensor(codes)\n",
    "\n",
    "\n",
    "def gen_discrete_code(n_instance, n_discrete, num_category=10):\n",
    "    \"\"\"generate discrete codes with n categories\"\"\"\n",
    "    codes = []\n",
    "    for i in range(n_discrete):\n",
    "        code = np.zeros((n_instance, num_category))\n",
    "        random_cate = np.random.randint(0, num_category, n_instance)\n",
    "        code[range(n_instance), random_cate] = 1\n",
    "        codes.append(code)\n",
    "\n",
    "    codes = np.concatenate(codes, 1)\n",
    "    return torch.Tensor(codes)\n",
    "\n",
    "\n",
    "def train_InfoGAN(InfoGAN_Dis, InfoGAN_Gen, D_criterion, G_criterion,\n",
    "                  D_optimizer, G_optimizer, info_reg_discrete, info_reg_conti,\n",
    "                  n_conti, n_discrete, mean, std, num_category, trainloader,\n",
    "                  n_epoch, batch_size, noise_dim,\n",
    "                  n_update_dis=1, n_update_gen=1, use_gpu=False,\n",
    "                  print_every=50, update_max=None):\n",
    "    \"\"\"train InfoGAN and print out the losses for D and G\"\"\"\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "\n",
    "        D_running_loss = 0.0\n",
    "        G_running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs from true distribution\n",
    "            true_inputs, lab = data\n",
    "            true_inputs = Variable(true_inputs)\n",
    "            if use_gpu:\n",
    "                true_inputs = true_inputs.cuda()\n",
    "\n",
    "            # get inputs (noises and codes) for Generator\n",
    "            noises = Variable(gen_noise(batch_size, n_dim=noise_dim))\n",
    "            conti_codes = Variable(gen_conti_codes(batch_size, n_conti,\n",
    "                                                   mean, std))\n",
    "            discr_codes = Variable(gen_discrete_code(batch_size, n_discrete,\n",
    "                                                     num_category))\n",
    "            if use_gpu:\n",
    "                noises = noises.cuda()\n",
    "                conti_codes = conti_codes.cuda()\n",
    "                discr_codes = discr_codes.cuda()\n",
    "\n",
    "            # generate fake images\n",
    "            gen_inputs = torch.cat((noises, conti_codes, discr_codes), 1)\n",
    "            fake_inputs = InfoGAN_Gen(gen_inputs)\n",
    "            vutils.save_image(fake_inputs.data, 'fake_samples.png')\n",
    "            \n",
    "            inputs = torch.cat([true_inputs, fake_inputs])\n",
    "\n",
    "            # make a minibatch of labels\n",
    "            labels = np.zeros(2 * batch_size)\n",
    "            labels[:batch_size] = 1\n",
    "            labels = torch.from_numpy(labels.astype(np.float32))\n",
    "            if use_gpu:\n",
    "                labels = labels.cuda()\n",
    "            labels = Variable(labels)\n",
    "\n",
    "            # Discriminator\n",
    "            D_optimizer.zero_grad()\n",
    "            outputs = InfoGAN_Dis(inputs)\n",
    "\n",
    "            # calculate mutual information lower bound L(G, Q)\n",
    "            for j in range(n_discrete):\n",
    "                shift = (j * num_category)\n",
    "                start = 1 + n_conti + shift\n",
    "                end = start + num_category\n",
    "                Q_cx_discr = outputs[batch_size:, start:end]\n",
    "                codes = discr_codes[:, shift:(shift+num_category)]\n",
    "                condi_entro = -torch.mean(torch.sum(Q_cx_discr * codes, 1))\n",
    "\n",
    "                if j == 0:\n",
    "                    L_discrete = -condi_entro\n",
    "                else:\n",
    "                    L_discrete -= condi_entro\n",
    "            L_discrete /= n_discrete\n",
    "\n",
    "            Q_cx_conti = outputs[batch_size:, 1:(1 + n_conti)]\n",
    "            L_conti = torch.mean(-(((Q_cx_conti - mean) / std) ** 2))\n",
    "\n",
    "            # Update Discriminator\n",
    "            D_loss = D_criterion(outputs[:, 0], labels)\n",
    "            if n_discrete > 0:\n",
    "                D_loss = D_loss - info_reg_discrete * L_discrete\n",
    "\n",
    "            if n_conti > 0:\n",
    "                D_loss = D_loss - info_reg_conti * L_conti\n",
    "\n",
    "            if i % n_update_dis == 0:\n",
    "                D_loss.backward(retain_variables=True)\n",
    "                D_optimizer.step()\n",
    "\n",
    "            # Update Generator\n",
    "            if i % n_update_gen == 0:\n",
    "                G_optimizer.zero_grad()\n",
    "                G_loss = G_criterion(outputs[batch_size:, 0],\n",
    "                                     labels[:batch_size])\n",
    "\n",
    "                if n_discrete > 0:\n",
    "                    G_loss = G_loss - info_reg_discrete * L_discrete\n",
    "\n",
    "                if n_conti > 0:\n",
    "                    G_loss = G_loss - info_reg_conti * L_conti\n",
    "\n",
    "                G_loss.backward()\n",
    "                G_optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            D_running_loss += D_loss.data[0]\n",
    "            G_running_loss += G_loss.data[0]\n",
    "            if i % print_every == (print_every - 1):\n",
    "                print('[%d, %5d] D loss: %.3f ; G loss: %.3f' %\n",
    "                      (epoch+1, i+1, D_running_loss / print_every,\n",
    "                       G_running_loss / print_every))\n",
    "                D_running_loss = 0.0\n",
    "                G_running_loss = 0.0\n",
    "\n",
    "            if update_max and i > update_max:\n",
    "                break\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "def run_InfoGAN(info_reg_discrete=1.0, info_reg_conti=0.5, noise_dim=10,\n",
    "                n_conti=2, n_discrete=1, mean=0.0, std=0.5, num_category=10,\n",
    "                n_layer=3, n_channel=1, D_featmap_dim=256, G_featmap_dim=1024,\n",
    "                n_epoch=2, batch_size=50, use_gpu=False, dis_lr=1e-4,\n",
    "                gen_lr=1e-3, n_update_dis=1, n_update_gen=1, update_max=None):\n",
    "    # loading data\n",
    "    trainloader, testloader = load_dataset(batch_size=batch_size)\n",
    "\n",
    "    # initialize models\n",
    "    InfoGAN_Dis = InfoGAN_Discriminator(n_layer, n_conti, n_discrete,\n",
    "                                        num_category, use_gpu, D_featmap_dim,\n",
    "                                        n_channel)\n",
    "\n",
    "    InfoGAN_Gen = InfoGAN_Generator(noise_dim, n_layer, n_conti, n_discrete,\n",
    "                                    num_category, use_gpu, G_featmap_dim,\n",
    "                                    n_channel)\n",
    "\n",
    "    if use_gpu:\n",
    "        InfoGAN_Dis = InfoGAN_Dis.cuda()\n",
    "        InfoGAN_Gen = InfoGAN_Gen.cuda()\n",
    "\n",
    "    # assign loss function and optimizer (Adam) to D and G\n",
    "    D_criterion = torch.nn.BCELoss()\n",
    "    D_optimizer = optim.Adam(InfoGAN_Dis.parameters(), lr=dis_lr,\n",
    "                             betas=(0.5, 0.999))\n",
    "\n",
    "    G_criterion = torch.nn.BCELoss()\n",
    "    G_optimizer = optim.Adam(InfoGAN_Gen.parameters(), lr=gen_lr,\n",
    "                             betas=(0.5, 0.999))\n",
    "\n",
    "    train_InfoGAN(InfoGAN_Dis, InfoGAN_Gen, D_criterion, G_criterion,\n",
    "                  D_optimizer, G_optimizer, info_reg_discrete, info_reg_conti,\n",
    "                  n_conti, n_discrete, mean, std, num_category, trainloader,\n",
    "                  n_epoch, batch_size, noise_dim,\n",
    "                  n_update_dis, n_update_gen, use_gpu, update_max=update_max)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_InfoGAN(n_conti=2, n_discrete=1, D_featmap_dim=64, G_featmap_dim=128,\n",
    "                n_epoch=25, batch_size=10, update_max=20000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8bbf50cdb0b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object does not support indexing"
     ]
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
